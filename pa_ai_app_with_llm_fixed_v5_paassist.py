# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
from io import BytesIO
from datetime import datetime
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from openai import OpenAI
import os
import io
from PyPDF2 import PdfReader

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏û‡∏à
st.set_page_config(page_title="Planning Studio (+ Issue Suggestions)", page_icon="üß≠", layout="wide")

# ----------------- ‚öôÔ∏è ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏•‡∏≤‡∏á -----------------
with st.sidebar:
    st.title("‚öôÔ∏è ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏•‡∏≤‡∏á")
    st.info("API Key ‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏≠‡∏Å‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏ó‡∏∏‡∏Å‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå AI ‡πÉ‡∏ô‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô")
    st.session_state.api_key_global = st.text_input(
        "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å API Key (OpenTyphoon)",
        type="password",
        key="api_key_global_input_sidebar",
        help="‡∏Ñ‡∏•‡∏¥‡∏Å‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ö Key ‡∏ü‡∏£‡∏µ: https://playground.opentyphoon.ai/settings/api-key"
    )
    st.markdown("---")
    st.markdown("Planning Studio Web App")

# ----------------- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Chatbot -----------------
MAX_CHARS_LIMIT = 200000

@st.cache_data(show_spinner=False)
def load_local_documents(folder_path="Doc"):
    """‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå 'Doc' ‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏"""
    text = ""
    if not os.path.isdir(folder_path):
        return text # ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå

    try:
        files_in_doc = os.listdir(folder_path)
        progress_bar = st.sidebar.progress(0, text=f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏à‡∏≤‡∏Å 'Doc'... (0/{len(files_in_doc)})")
        for i, filename in enumerate(files_in_doc):
            if len(text) >= MAX_CHARS_LIMIT:
                st.warning(f"‡∏ñ‡∏∂‡∏á‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå 'Doc' ‡πÅ‡∏•‡πâ‡∏ß ({MAX_CHARS_LIMIT:,} ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£)")
                break
            
            file_path = os.path.join(folder_path, filename)
            try:
                if filename.endswith('.pdf'):
                    with open(file_path, 'rb') as f:
                        reader = PdfReader(f)
                        for page in reader.pages:
                            text += page.extract_text() or ""
                elif filename.endswith('.txt'):
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        text += f.read()
                elif filename.endswith('.csv'):
                    df = pd.read_csv(file_path)
                    text += df.head(15).to_string()
            except Exception as e:
                print(f"Could not read file {filename}: {e}")
            
            progress_bar.progress((i + 1) / len(files_in_doc), text=f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£... ({i+1}/{len(files_in_doc)})")
        progress_bar.empty()
                
    except Exception as e:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå 'Doc': {e}")
    
    return text[:MAX_CHARS_LIMIT]

def process_documents(files, source_type, limit, current_len=0):
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î"""
    text = ""
    for file in files:
        if current_len + len(text) >= limit:
            st.warning(f"‡∏ñ‡∏∂‡∏á‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î ({limit:,}) ‡πÅ‡∏•‡πâ‡∏ß ‡πÑ‡∏ü‡∏•‡πå‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•")
            break
        try:
            if file.name.endswith('.pdf'):
                reader = PdfReader(file)
                for page in reader.pages:
                    text += page.extract_text() or ""
            elif file.name.endswith('.txt'):
                text += file.getvalue().decode("utf-8")
            elif file.name.endswith('.csv'):
                df = pd.read_csv(file)
                text += df.head(15).to_string()
        except Exception as e:
            st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå {file.name}: {e}")
    return text[:limit - current_len], [f.name for f in files]

# ----------------- Session Init -----------------
def init_state():
    ss = st.session_state
    ss.setdefault("plan", {"plan_id": "PLN-" + datetime.now().strftime("%y%m%d-%H%M%S"),"plan_title": "","program_name": "","who": "", "what": "", "where": "", "when": "", "why": "", "how": "", "how_much": "", "whom": "","objectives": "", "scope": "", "assumptions": "", "status": "Draft"})
    ss.setdefault("logic_items", pd.DataFrame(columns=["item_id","plan_id","type","description","metric","unit","target","source"]))
    ss.setdefault("methods", pd.DataFrame(columns=["method_id","plan_id","type","tool_ref","sampling","questions","linked_issue","data_source","frequency"]))
    ss.setdefault("kpis", pd.DataFrame(columns=["kpi_id","plan_id","level","name","formula","numerator","denominator","unit","baseline","target","frequency","data_source","quality_requirements"]))
    ss.setdefault("risks", pd.DataFrame(columns=["risk_id","plan_id","description","category","likelihood","impact","mitigation","hypothesis"]))
    ss.setdefault("audit_issues", pd.DataFrame(columns=["issue_id","plan_id","title","rationale","linked_kpi","proposed_methods","source_finding_id","issue_detail", "recommendation"]))
    ss.setdefault("gen_issues", "")
    ss.setdefault("gen_findings", "")
    ss.setdefault("gen_report", "")
    ss.setdefault("issue_results", pd.DataFrame())
    ss.setdefault("ref_seed", "")
    ss.setdefault("issue_query_text", "")
    ss.setdefault('api_key_global', '')
    
    ss.setdefault('chatbot_messages', [{"role": "assistant", "content": "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ú‡∏°‡∏Ñ‡∏∑‡∏≠ PA Chat ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö"}])
    ss.setdefault('doc_context_uploaded', "")
    ss.setdefault('last_uploaded_files', set())

    if 'doc_context_local' not in ss:
        ss.doc_context_local = load_local_documents()
        if ss.doc_context_local and os.path.isdir('Doc'):
             ss.chatbot_messages.append({"role": "assistant", "content": f"‡∏ú‡∏°‡πÑ‡∏î‡πâ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ {len(os.listdir('Doc'))} ‡∏â‡∏ö‡∏±‡∏ö‡∏à‡∏≤‡∏Å‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå 'Doc' ‡πÄ‡∏õ‡πá‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏£‡∏±‡∏ö"})

def next_id(prefix, df, col):
    if df.empty: return f"{prefix}-001"
    nums = []
    for x in df[col]:
        try: nums.append(int(str(x).split("-")[-1]))
        except: pass
    n = max(nums) + 1 if nums else 1
    return f"{prefix}-{n:03d}"

def df_download_link(df: pd.DataFrame, filename: str, label: str):
    buf = BytesIO()
    df.to_csv(buf, index=False, encoding="utf-8-sig")
    st.download_button(label, data=buf.getvalue(), file_name=filename, mime="text/csv")

@st.cache_data(show_spinner=False)
def load_findings(uploaded=None):
    findings_df = pd.DataFrame()
    findings_db_path = "FindingsLibrary.csv"
    if os.path.exists(findings_db_path):
        try: findings_df = pd.read_csv(findings_db_path)
        except Exception as e: st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå FindingsLibrary.csv: {e}")
    if uploaded is not None:
        try:
            if uploaded.name.endswith('.csv'): uploaded_df = pd.read_csv(uploaded)
            elif uploaded.name.endswith(('.xlsx', '.xls')):
                xls = pd.ExcelFile(uploaded)
                sheet_name = "Data" if "Data" in xls.sheet_names else 0
                uploaded_df = pd.read_excel(xls, sheet_name=sheet_name)
            if not uploaded_df.empty:
                findings_df = pd.concat([findings_df, uploaded_df], ignore_index=True)
                st.success(f"‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå '{uploaded.name}' ‡πÅ‡∏•‡∏∞‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ö‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏î‡∏¥‡∏°‡πÅ‡∏•‡πâ‡∏ß")
        except Exception as e: st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î: {e}")
    if not findings_df.empty:
        for c in ["issue_title","issue_detail","cause_detail","recommendation","program","unit"]:
            if c in findings_df.columns: findings_df[c] = findings_df[c].fillna("")
        if "year" in findings_df.columns: findings_df["year"] = pd.to_numeric(findings_df["year"], errors="coerce").fillna(0).astype(int)
        if "severity" in findings_df.columns: findings_df["severity"] = pd.to_numeric(findings_df["severity"], errors="coerce").fillna(3).clip(1,5).astype(int)
    return findings_df

@st.cache_resource(show_spinner=False)
def build_tfidf_index(findings_df: pd.DataFrame):
    texts = (findings_df["issue_title"].fillna("") + " " + findings_df["issue_detail"].fillna("") + " " + findings_df["cause_detail"].fillna("") + " " + findings_df["recommendation"].fillna(""))
    vec = TfidfVectorizer(max_features=20000, ngram_range=(1,2))
    X = vec.fit_transform(texts)
    return vec, X

def search_candidates(query_text, findings_df, vec, X, top_k=8):
    qv = vec.transform([query_text])
    sims = cosine_similarity(qv, X)[0]
    out = findings_df.copy()
    out["sim_score"] = sims
    out["year_norm"] = (out["year"] - out["year"].min()) / (out["year"].max() - out["year"].min()) if "year" in out.columns and out["year"].max() != out["year"].min() else 0.0
    out["sev_norm"] = out.get("severity", 3) / 5
    out["score"] = out["sim_score"]*0.65 + out["sev_norm"]*0.25 + out["year_norm"]*0.10
    cols = ["finding_id","year","unit","program","issue_title","issue_detail","cause_category","cause_detail","recommendation","outcomes_impact","severity","score", "sim_score"]
    return out.sort_values("score", ascending=False).head(top_k)[[c for c in cols if c in out.columns]]
    
def create_excel_template():
    df = pd.DataFrame(columns=["finding_id", "issue_title", "unit", "program", "year", "cause_category", "cause_detail", "issue_detail", "recommendation", "outcomes_impact", "severity"])
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer: df.to_excel(writer, index=False, sheet_name='FindingsLibrary')
    return output.getvalue()

init_state()
plan = st.session_state["plan"]
logic_df = st.session_state["logic_items"]
methods_df = st.session_state["methods"]
kpis_df = st.session_state["kpis"]
risks_df = st.session_state["risks"]
audit_issues_df = st.session_state["audit_issues"]

st.title("üß≠ Planning Studio ‚Äì Performance Audit")

st.markdown("""<style> body { font-family: 'Kanit', sans-serif; } button[data-baseweb="tab"] { border: 1px solid #007bff; border-radius: 8px; padding: 10px 15px; margin: 5px 5px 5px 0px; font-weight: bold; color: #007bff !important; background-color: #ffffff; box-shadow: 1px 1px 3px rgba(0, 0, 0, 0.1); border-bottom: none !important; &::after { content: none !important; } } button[data-baseweb="tab"][aria-selected="true"] { box-shadow: 2px 2px 5px rgba(0,0,0,0.2); } div[data-baseweb="tab-list"] button:nth-of-type(-n+5) { border-color: #007bff; color: #007bff !important; } div[data-baseweb="tab-list"] button:nth-of-type(-n+5)[aria-selected="true"] { background-color: #007bff; color: white !important; } div[data-baseweb="tab-list"] button:nth-of-type(6), div[data-baseweb="tab-list"] button:nth-of-type(7) { border-color: #6f42c1; color: #6f42c1 !important; } div[data-baseweb="tab-list"] button:nth-of-type(6)[aria-selected="true"], div[data-baseweb="tab-list"] button:nth-of-type(7)[aria-selected="true"] { background-color: #6f42c1; color: white !important; } div[data-baseweb="tab-list"] button:nth-of-type(8) { border-color: #ffc107; color: #cc9900 !important; } div[data-baseweb="tab-list"] button:nth-of-type(8)[aria-selected="true"] { background-color: #ffc107; color: #333333 !important; } div[data-baseweb="tab-list"] button:nth-of-type(9) { border-color: #28a745; color: #28a745 !important; } div[data-baseweb="tab-list"] button:nth-of-type(9)[aria-selected="true"] { background-color: #28a745; color: white !important; } div[data-baseweb="tab-list"] { border-bottom: none !important; margin-bottom: 15px; flex-wrap: wrap; gap: 10px; } h4 { color: #007bff !important; border-bottom: 2px solid #e0e0e0; padding-bottom: 5px; } </style>""", unsafe_allow_html=True)

tab_plan, tab_logic, tab_method, tab_kpi, tab_risk, tab_issue, tab_preview, tab_assist, tab_chatbot = st.tabs(["1. ‡∏£‡∏∞‡∏ö‡∏∏ ‡πÅ‡∏ú‡∏ô & 6W2H", "2. ‡∏£‡∏∞‡∏ö‡∏∏ Logic Model", "3. ‡∏£‡∏∞‡∏ö‡∏∏ Methods", "4. ‡∏£‡∏∞‡∏ö‡∏∏ KPIs", "5. ‡∏£‡∏∞‡∏ö‡∏∏ Risks", "6. ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏°‡∏≤", "7. ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Preview)", "ü§ñ ‡πÉ‡∏´‡πâ PA Assist ‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö ‚ú®‚ú®", "üí¨ PA Chat (‡∏ñ‡∏≤‡∏°-‡∏ï‡∏≠‡∏ö)"]) 

with tab_plan:
    st.subheader("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ú‡∏ô (Plan) - ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏∞‡∏ö‡∏∏‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
    with st.container(border=True):
        c1, c2, c3 = st.columns([2,2,1])
        plan["plan_title"] = c1.text_input("‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏ú‡∏ô/‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ï‡∏£‡∏ß‡∏à", plan["plan_title"])
        plan["program_name"] = c1.text_input("‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£/‡πÅ‡∏ú‡∏ô‡∏á‡∏≤‡∏ô", plan["program_name"])
        plan["objectives"] = c1.text_area("‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à", plan["objectives"])
        plan["scope"] = c2.text_area("‡∏Ç‡∏≠‡∏ö‡πÄ‡∏Ç‡∏ï‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à", plan["scope"])
        plan["assumptions"] = c2.text_area("‡∏™‡∏°‡∏°‡∏∏‡∏ï‡∏¥‡∏ê‡∏≤‡∏ô/‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", plan["assumptions"])
        c3.text_input("Plan ID", plan["plan_id"], disabled=True)
        plan["status"] = c3.selectbox("‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞", ["Draft","Published"], index=0)

    st.divider()
    st.subheader("‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö (6W2H)")
    with st.container(border=True):
        st.markdown("##### üöÄ ‡∏™‡∏£‡πâ‡∏≤‡∏á 6W2H ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏î‡πâ‡∏ß‡∏¢ AI")
        uploaded_text = st.text_area("‡∏£‡∏∞‡∏ö‡∏∏‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ AI ‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏£‡∏∏‡∏õ 6W2H", height=200, key="uploaded_text")
        
        if st.button("üöÄ ‡∏™‡∏£‡πâ‡∏≤‡∏á 6W2H ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°", type="primary", key="6w2h_button"):
            if not uploaded_text: st.error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ß‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏ô‡∏ä‡πà‡∏≠‡∏á‡∏Å‡πà‡∏≠‡∏ô")
            elif not st.session_state.api_key_global: st.error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å API Key ‡∏ó‡∏µ‡πà Sidebar ‡∏î‡πâ‡∏≤‡∏ô‡∏ã‡πâ‡∏≤‡∏¢‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
            else:
                with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•..."):
                    try:
                        user_prompt = f"‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏•‡∏∞‡πÅ‡∏¢‡∏Å‡πÅ‡∏¢‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô 6W2H ‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πà Who, Whom, What, Where, When, Why, How, ‡πÅ‡∏•‡∏∞ How much ‡πÇ‡∏î‡∏¢‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö key-value ‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô\n‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: --- {uploaded_text} ---"
                        client = OpenAI(api_key=st.session_state.api_key_global, base_url="https://api.opentyphoon.ai/v1")
                        response = client.chat.completions.create(model="typhoon-v2.1-12b-instruct", messages=[{"role": "user", "content": user_prompt}], temperature=0.7, max_tokens=1024, top_p=0.9)
                        llm_output = response.choices[0].message.content
                        for line in llm_output.strip().split('\n'):
                            if ':' in line:
                                key, value = line.split(':', 1)
                                normalized_key = key.strip().lower().replace(' ', '_')
                                if normalized_key in st.session_state.plan: st.session_state.plan[normalized_key] = value.strip()
                        st.success("‡∏™‡∏£‡πâ‡∏≤‡∏á 6W2H ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß! ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á")
                        st.balloons()
                    except Exception as e: st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ AI: {e}")
        
    st.markdown("##### ‚≠ê‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏∞‡∏ö‡∏∏‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏≥‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•")
    with st.container(border=True):
        cc1, cc2, cc3 = st.columns(3)
        st.session_state.plan["who"] = cc1.text_input("Who (‡πÉ‡∏Ñ‡∏£)", value=st.session_state.plan["who"], key="who_input")
        st.session_state.plan["whom"] = cc1.text_input("Whom (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏Ñ‡∏£)", value=st.session_state.plan["whom"], key="whom_input")
        st.session_state.plan["what"] = cc1.text_input("What (‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£)", value=st.session_state.plan["what"], key="what_input")
        st.session_state.plan["where"] = cc1.text_input("Where (‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô)", value=st.session_state.plan["where"], key="where_input")
        st.session_state.plan["when"] = cc2.text_input("When (‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÉ‡∏î)", value=st.session_state.plan["when"], key="when_input")
        st.session_state.plan["why"] = cc2.text_area("Why (‡∏ó‡∏≥‡πÑ‡∏°)", value=st.session_state.plan["why"], key="why_input")
        st.session_state.plan["how"] = cc3.text_area("How (‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£)", value=st.session_state.plan["how"], key="how_input")
        st.session_state.plan["how_much"] = cc3.text_input("How much (‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏£)", value=st.session_state.plan["how_much"], key="how_much_input")

with tab_logic:
    st.subheader("‡∏£‡∏∞‡∏ö‡∏∏‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Logic Model: Input ‚Üí Activities ‚Üí Output ‚Üí Outcome ‚Üí Impact")
    st.dataframe(logic_df, use_container_width=True, hide_index=True)
    with st.expander("‚ûï ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÉ‡∏ô Logic Model"):
        with st.container(border=True):
            colA, colB, colC = st.columns(3)
            typ = colA.selectbox("‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó", ["Input","Activity","Output","Outcome","Impact"])
            desc = colA.text_input("‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢/‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î")
            metric = colA.text_input("‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î/metric (‡πÄ‡∏ä‡πà‡∏ô ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô, ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô)")
            unit = colB.text_input("‡∏´‡∏ô‡πà‡∏ß‡∏¢", value="‡∏´‡∏ô‡πà‡∏ß‡∏¢", key="logic_unit")
            target = colB.text_input("‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢", value="", key="logic_target")
            source = colC.text_input("‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", value="", key="logic_source")
            if st.button("‡πÄ‡∏û‡∏¥‡πà‡∏° Logic Item", type="primary"):
                new_row = pd.DataFrame([{"item_id": next_id("LG", logic_df, "item_id"),"plan_id": plan["plan_id"],"type": typ, "description": desc, "metric": metric,"unit": unit, "target": target, "source": source}])
                st.session_state["logic_items"] = pd.concat([logic_df, new_row], ignore_index=True)
                st.rerun()

with tab_method:
    st.subheader("‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Methods)")
    st.dataframe(methods_df, use_container_width=True, hide_index=True)
    with st.expander("‚ûï ‡πÄ‡∏û‡∏¥‡πà‡∏° Method"):
        with st.container(border=True):
            c1, c2, c3 = st.columns(3)
            mtype = c1.selectbox("‡∏ä‡∏ô‡∏¥‡∏î", ["observe","interview","questionnaire","document"])
            tool_ref = c1.text_input("‡∏£‡∏´‡∏±‡∏™/‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠", value="")
            sampling = c1.text_input("‡∏ß‡∏¥‡∏ò‡∏µ‡∏Ñ‡∏±‡∏î‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á", value="")
            questions = c2.text_area("‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°/‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å")
            linked_issue = c2.text_input("‡πÇ‡∏¢‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏ï‡∏£‡∏ß‡∏à", value="")
            data_source = c3.text_input("‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", value="", key="method_data_source")
            frequency = c3.text_input("‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà", value="‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß", key="method_frequency")
            if st.button("‡πÄ‡∏û‡∏¥‡πà‡∏° Method", type="primary", key="add_method_btn"):
                new_row = pd.DataFrame([{"method_id": next_id("MT", methods_df, "method_id"),"plan_id": plan["plan_id"],"type": mtype, "tool_ref": tool_ref, "sampling": sampling,"questions": questions, "linked_issue": linked_issue,"data_source": data_source, "frequency": frequency}])
                st.session_state["methods"] = pd.concat([methods_df, new_row], ignore_index=True)
                st.rerun()

with tab_kpi:
    st.subheader("‡∏£‡∏∞‡∏ö‡∏∏‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î (KPIs)")
    st.dataframe(kpis_df, use_container_width=True, hide_index=True)
    with st.expander("‚ûï ‡πÄ‡∏û‡∏¥‡πà‡∏° KPI ‡πÄ‡∏≠‡∏á"):
        with st.container(border=True):
            col1, col2, col3 = st.columns(3)
            level = col1.selectbox("‡∏£‡∏∞‡∏î‡∏±‡∏ö", ["output","outcome"])
            name = col1.text_input("‡∏ä‡∏∑‡πà‡∏≠ KPI")
            formula = col1.text_input("‡∏™‡∏π‡∏ï‡∏£/‡∏ô‡∏¥‡∏¢‡∏≤‡∏°")
            numerator = col2.text_input("‡∏ï‡∏±‡∏ß‡∏ï‡∏±‡πâ‡∏á (numerator)")
            denominator = col2.text_input("‡∏ï‡∏±‡∏ß‡∏´‡∏≤‡∏£ (denominator)")
            unit = col2.text_input("‡∏´‡∏ô‡πà‡∏ß‡∏¢", value="%", key="kpi_unit")
            baseline = col3.text_input("Baseline", value="")
            target = col3.text_input("Target", value="")
            freq = col3.text_input("‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà", value="‡∏£‡∏≤‡∏¢‡πÑ‡∏ï‡∏£‡∏°‡∏≤‡∏™")
            data_src = col3.text_input("‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", value="", key="kpi_data_source")
            quality = col3.text_input("‡∏Ç‡πâ‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", value="‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á/‡∏ó‡∏±‡∏ô‡πÄ‡∏ß‡∏•‡∏≤", key="kpi_quality")
            if st.button("‡πÄ‡∏û‡∏¥‡πà‡∏° KPI", type="primary", key="add_kpi_btn"):
                new_row = pd.DataFrame([{"kpi_id": next_id("KPI", kpis_df, "kpi_id"),"plan_id": plan["plan_id"],"level": level, "name": name, "formula": formula,"numerator": numerator, "denominator": denominator, "unit": unit,"baseline": baseline, "target": target, "frequency": freq,"data_source": data_src, "quality_requirements": quality}])
                st.session_state["kpis"] = pd.concat([kpis_df, new_row], ignore_index=True)
                st.rerun()

with tab_risk:
    st.subheader("‡∏£‡∏∞‡∏ö‡∏∏‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á (Risks)")
    st.dataframe(risks_df, use_container_width=True, hide_index=True)
    with st.expander("‚ûï ‡πÄ‡∏û‡∏¥‡πà‡∏° Risk"):
        with st.container(border=True):
            c1, c2, c3 = st.columns(3)
            desc = c1.text_area("‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á")
            category = c1.selectbox("‡∏´‡∏°‡∏ß‡∏î", ["policy","org","data","process","people"])
            likelihood = c2.select_slider("‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡πÄ‡∏Å‡∏¥‡∏î (1-5)", options=[1,2,3,4,5], value=3)
            impact = c2.select_slider("‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö (1-5)", options=[1,2,3,4,5], value=3)
            mitigation = c3.text_area("‡∏°‡∏≤‡∏ï‡∏£‡∏Å‡∏≤‡∏£‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á")
            hypothesis = c3.text_input("‡∏™‡∏°‡∏°‡∏∏‡∏ï‡∏¥‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏î‡∏™‡∏≠‡∏ö")
            if st.button("‡πÄ‡∏û‡∏¥‡πà‡∏° Risk", type="primary", key="add_risk_btn"):
                new_row = pd.DataFrame([{"risk_id": next_id("RSK", risks_df, "risk_id"),"plan_id": plan["plan_id"],"description": desc, "category": category,"likelihood": likelihood, "impact": impact,"mitigation": mitigation, "hypothesis": hypothesis}])
                st.session_state["risks"] = pd.concat([risks_df, new_row], ignore_index=True)
                st.rerun()

with tab_issue:
    st.subheader("üîé ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡πÄ‡∏Å‡πà‡∏≤ (Issue Suggestions)")

    # --- MODIFIED: ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏à‡∏≤‡∏Å container ‡πÄ‡∏õ‡πá‡∏ô expander ---
    with st.expander("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö (Findings Library)"):
        st.write("‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå .csv ‡∏´‡∏£‡∏∑‡∏≠ .xlsx ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡πÄ‡∏Å‡πà‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ ‡∏´‡∏£‡∏∑‡∏≠‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏°‡πà‡πÅ‡∏ö‡∏ö‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
        st.download_button(
            label="‚¨áÔ∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏°‡πà‡πÅ‡∏ö‡∏ö FindingsLibrary.xlsx",
            data=create_excel_template(),
            file_name="FindingsLibrary.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
        uploaded = st.file_uploader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î FindingsLibrary.csv ‡∏´‡∏£‡∏∑‡∏≠ .xlsx", type=["csv", "xlsx", "xls"], label_visibility="collapsed")
    
    findings_df = load_findings(uploaded=uploaded)
    
    if findings_df.empty:
        st.info("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Findings ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ô‡∏≥‡∏°‡∏≤‡πÉ‡∏ä‡πâ ‡πÇ‡∏õ‡∏£‡∏î‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå ‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå FindingsLibrary.csv ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô")
    else:
        st.success(f"‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Findings ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {len(findings_df)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        vec, X = build_tfidf_index(findings_df)
        
        seed = f"""
Who:{plan.get('who','')} What:{plan.get('what','')} Where:{plan.get('where','')}
When:{plan.get('when','')} Why:{plan.get('why','')} How:{plan.get('how','')}
Outputs:{' | '.join(logic_df[logic_df['type']=='Output']['description'].tolist())}
Outcomes:{' | '.join(logic_df[logic_df['type']=='Outcome']['description'].tolist())}
"""
        
        def refresh_query_text(new_seed):
            st.session_state["issue_query_text"] = new_seed
            st.session_state["ref_seed"] = new_seed 

        if "issue_query_text" not in st.session_state or st.session_state["issue_query_text"] == "":
            st.session_state["issue_query_text"] = seed
            st.session_state["ref_seed"] = seed
        elif st.session_state.get("ref_seed") != seed and st.session_state.get("issue_query_text") == st.session_state.get("ref_seed"):
            st.session_state["issue_query_text"] = seed
            st.session_state["ref_seed"] = seed 

        c_query_area, c_refresh_btn = st.columns([6, 1])
        with c_query_area:
            query_text = st.text_area(
                "**‡∏™‡∏£‡∏∏‡∏õ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ (‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÑ‡∏î‡πâ):**", 
                st.session_state["issue_query_text"], 
                height=140, 
                key="issue_query_text"
            )
        with c_refresh_btn:
            st.markdown("<br>", unsafe_allow_html=True)
            st.button(
                "üîÑ", 
                on_click=refresh_query_text,
                args=(seed,),
                help="‡∏Ñ‡∏•‡∏¥‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏ä‡πà‡∏≠‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î",
                type="secondary"
            )
        
        # --- NEW: ‡πÄ‡∏û‡∏¥‡πà‡∏° Slider ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå ---
        top_k_slider = st.slider("‡∏õ‡∏£‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á:", min_value=1, max_value=20, value=8)

        if st.button("‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á", type="primary", key="search_button_fix"):
            search_value = st.session_state.get("issue_query_text", seed)
            # --- MODIFIED: ‡∏™‡πà‡∏á‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å slider ‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô ---
            results = search_candidates(search_value, findings_df, vec, X, top_k=top_k_slider)
            st.session_state["issue_results"] = results
            st.success(f"‡∏û‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á {len(results)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
            
        results = st.session_state.get("issue_results", pd.DataFrame())
        
        if not results.empty:
            st.divider()
            st.subheader("‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤")
            for i, row in results.reset_index(drop=True).iterrows():
                with st.container(border=True):
                    title_txt = row.get("issue_title", "(‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô)")
                    year_txt = int(row["year"]) if "year" in row and str(row["year"]).isdigit() else row.get("year", "-")
                    st.markdown(f"**{title_txt}** \n‡∏´‡∏ô‡πà‡∏ß‡∏¢: {row.get('unit', '-')} ‚Ä¢ ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£: {row.get('program', '-')} ‚Ä¢ ‡∏õ‡∏µ {year_txt}")
                    st.caption(f"‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏: *{row.get('cause_category', '-')}* ‚Äî {row.get('cause_detail', '-')}")
    
                    with st.expander("‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î/‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞ (‡πÄ‡∏î‡∏¥‡∏°)"):
                        st.write(row.get("issue_detail", "-"))
                        st.caption("‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞‡πÄ‡∏î‡∏¥‡∏°: " + (row.get("recommendation", "") or "-"))
                        st.markdown(f"**‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô:** {row.get('outcomes_impact','-')}  ‚Ä¢  <span style='color:red;'>**‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á**</span>: {row.get('score',0):.3f} (<span style='color:blue;'>**Similarity Score**</span>={row.get('sim_score',0):.3f})", unsafe_allow_html=True)
                        st.caption("üí° **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢:** **‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á** = ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° + ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡∏Ç‡∏≠‡∏á‡∏õ‡∏±‡∏ç‡∏´‡∏≤ + ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏´‡∏°‡πà‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
    
                    c1, c2 = st.columns([3,1])
                    with c1:
                        st.text_area("‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏ï‡∏£‡∏ß‡∏à (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ú‡∏ô‡∏ô‡∏µ‡πâ)", key=f"rat_{i}", value=f"‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏Å‡∏£‡∏ì‡∏µ‡πÄ‡∏î‡∏¥‡∏° ‡∏õ‡∏µ {year_txt} | ‡∏´‡∏ô‡πà‡∏ß‡∏¢: {row.get('unit', '-')}")
                        st.text_input("KPI ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)", key=f"kpi_{i}")
                        st.text_input("‡∏ß‡∏¥‡∏ò‡∏µ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏™‡∏ô‡∏≠", key=f"mth_{i}", value="‡∏™‡∏±‡∏°‡∏†‡∏≤‡∏©‡∏ì‡πå/‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï/‡∏ï‡∏£‡∏ß‡∏à‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£")
    
                    with c2:
                        st.button(f"‚ûï ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÅ‡∏ú‡∏ô", key=f"add_{i}", type="secondary", on_click=lambda i=i, title=title_txt, r=row: (
                            st.session_state.update(audit_issues=pd.concat([st.session_state["audit_issues"], pd.DataFrame([{"issue_id": next_id("ISS", st.session_state["audit_issues"], "issue_id"),"plan_id": plan.get("plan_id",""),"title": title,"rationale": st.session_state.get(f"rat_{i}", ""),"linked_kpi": st.session_state.get(f"kpi_{i}", ""),"proposed_methods": st.session_state.get(f"mth_{i}", ""),"source_finding_id": r.get("finding_id", ""),"issue_detail": r.get("issue_detail", ""),"recommendation": r.get("recommendation", "")}])], ignore_index=True))
                        ))
                            
        if not st.session_state.get("issue_results", pd.DataFrame()).empty:
            st.divider()
        st.markdown("### ‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÅ‡∏ú‡∏ô")
        st.dataframe(st.session_state["audit_issues"], use_container_width=True, hide_index=True)
with tab_preview:
    st.subheader("‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏ú‡∏ô (Preview)")
    with st.container(border=True):
        st.markdown(f"**Plan ID:** {plan['plan_id']}  \n**‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏ú‡∏ô‡∏á‡∏≤‡∏ô:** {plan['plan_title']}  \n**‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£:** {plan['program_name']}  \n**‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à:** {plan['who']}")
    st.markdown("### ‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö (‡∏à‡∏≤‡∏Å 6W2H)")
    with st.container(border=True):
        st.markdown(f"- **Who**: {plan['who']}\n- **Whom**: {plan['whom']}\n- **What**: {plan['what']}\n- **Where**: {plan['where']}\n- **When**: {plan['when']}\n- **Why**: {plan['why']}\n- **How**: {plan['how']}\n- **How much**: {plan['how_much']}")
    c1, c2 = st.columns(2)
    with c1:
        st.markdown("### Logic Model")
        st.dataframe(st.session_state["logic_items"], use_container_width=True, hide_index=True)
        df_download_link(st.session_state["logic_items"], "logic_items.csv", "‚¨áÔ∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î Logic Items (CSV)")
    with c2:
        st.markdown("### Methods")
        st.dataframe(st.session_state["methods"], use_container_width=True, hide_index=True)
        df_download_link(st.session_state["methods"], "methods.csv", "‚¨áÔ∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î Methods (CSV)")
    c3, c4 = st.columns(2)
    with c3:
        st.markdown("### KPIs")
        st.dataframe(st.session_state["kpis"], use_container_width=True, hide_index=True)
        df_download_link(st.session_state["kpis"], "kpis.csv", "‚¨áÔ∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î KPIs (CSV)")
    with c4:
        st.markdown("### Risks")
        st.dataframe(st.session_state["risks"], use_container_width=True, hide_index=True)
        df_download_link(st.session_state["risks"], "risks.csv", "‚¨áÔ∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î Risks (CSV)")
    st.markdown("### Audit Issues ‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤")
    if not st.session_state["audit_issues"].empty:
        display_issues_df = st.session_state["audit_issues"].copy().rename(columns={"issue_id": "‡∏£‡∏´‡∏±‡∏™‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô", "title": "‡∏ä‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô","rationale": "‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏ï‡∏£‡∏ß‡∏à", "issue_detail": "‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î","recommendation": "‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞"})
        display_cols = ["‡∏£‡∏´‡∏±‡∏™‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô", "‡∏ä‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô", "‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏ï‡∏£‡∏ß‡∏à", "‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î", "‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞"]
        st.dataframe(display_issues_df[display_cols], use_container_width=True, hide_index=True)
    else:
        st.info("‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤‡πÉ‡∏ô‡πÅ‡∏ú‡∏ô")
    if not st.session_state["audit_issues"].empty:
        df_download_link(st.session_state["audit_issues"], "audit_issues.csv", "‚¨áÔ∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î Audit Issues (CSV)")
    st.divider()
    plan_df = pd.DataFrame([plan])
    df_download_link(plan_df, "plan.csv", "‚¨áÔ∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î Plan (CSV)")
    st.success("‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° Glide / Sheets ‡∏ï‡πà‡∏≠‡πÑ‡∏î‡πâ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ")

with tab_assist:
    st.subheader("üí° PA Audit Assist (‡∏Ç‡∏±‡∏ö‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏î‡πâ‡∏ß‡∏¢ LLM)")
    st.write("ü§ñ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏à‡∏≤‡∏Å AI")

    if st.button("üöÄ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏à‡∏≤‡∏Å AI", type="primary", key="llm_assist_button"):
        if not st.session_state.api_key_global:
            st.error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å API Key ‡∏ó‡∏µ‡πà Sidebar ‡∏î‡πâ‡∏≤‡∏ô‡∏ã‡πâ‡∏≤‡∏¢‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
        else:
            with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥..."):
                try:
                    issues_for_llm = st.session_state['audit_issues'][['title', 'rationale']]
                    plan_summary = f"""
‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏ú‡∏ô/‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ï‡∏£‡∏ß‡∏à: {plan['plan_title']}
‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£/‡πÅ‡∏ú‡∏ô‡∏á‡∏≤‡∏ô: {plan['program_name']}
‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå: {plan['objectives']}
‡∏Ç‡∏≠‡∏ö‡πÄ‡∏Ç‡∏ï: {plan['scope']}
‡∏™‡∏°‡∏°‡∏∏‡∏ï‡∏¥‡∏ê‡∏≤‡∏ô/‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î: {plan['assumptions']}
---
6W2H:
‡πÉ‡∏Ñ‡∏£ (Who): {plan['who']}
‡∏ñ‡∏∂‡∏á‡πÉ‡∏Ñ‡∏£ (Whom): {plan['whom']}
‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£ (What): {plan['what']}
‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô (Where): {plan['where']}
‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÉ‡∏î (When): {plan['when']}
‡∏ó‡∏≥‡πÑ‡∏° (Why): {plan['why']}
‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£ (How): {plan['how']}
‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏£ (How much): {plan['how_much']}
---
Logic Model:
{st.session_state['logic_items'].to_string()}
---
‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡πÄ‡∏Å‡πà‡∏≤:
{issues_for_llm.to_string()}
"""
                    user_prompt = f"""
‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ 3 ‡∏≠‡∏¢‡πà‡∏≤‡∏á ‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πà
1. ‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
2. ‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏û‡∏ö (‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏à‡∏≠: ‡∏™‡∏π‡∏á/‡∏Å‡∏•‡∏≤‡∏á/‡∏ï‡πà‡∏≥)
3. ‡∏£‡πà‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏à‡∏≠
---
{plan_summary}
---
‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ï‡∏≤‡∏°‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô:
<‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç>
[‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 1]
</‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç>

<‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏û‡∏ö>
[‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 2]
</‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏û‡∏ö>

<‡∏£‡πà‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏à‡∏≠>
[‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 3]
</‡∏£‡πà‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏à‡∏≠>
"""

                    client = OpenAI(
                        api_key=st.session_state.api_key_global,
                        base_url="https://api.opentyphoon.ai/v1"
                    )
                    
                    messages = [
                        {"role": "system", "content": "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ú‡∏•‡∏™‡∏±‡∏°‡∏§‡∏ó‡∏ò‡∏¥‡πå‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô (Performance Audit)"},
                        {"role": "user", "content": user_prompt}
                    ]
                    
                    response = client.chat.completions.create(
                        model="typhoon-v2.1-12b-instruct",
                        messages=messages,
                        temperature=0.7,
                        max_tokens=2048,
                    )

                    full_response = response.choices[0].message.content

                    issue_start = full_response.find("<‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç>") + len("<‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç>")
                    issue_end = full_response.find("</‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç>")
                    issues_text = full_response[issue_start:issue_end].strip()
                    
                    finding_start = full_response.find("<‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏û‡∏ö>") + len("<‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏û‡∏ö>")
                    finding_end = full_response.find("</‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏û‡∏ö>")
                    findings_text = full_response[finding_start:finding_end].strip()

                    report_start = full_response.find("<‡∏£‡πà‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏à‡∏≠>") + len("<‡∏£‡πà‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏à‡∏≠>")
                    report_end = full_response.find("</‡∏£‡πà‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏à‡∏≠>")
                    report_text = full_response[report_start:report_end].strip()

                    st.session_state["gen_issues"] = issues_text
                    st.session_state["gen_findings"] = findings_text
                    st.session_state["gen_report"] = report_text

                    st.success("‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏à‡∏≤‡∏Å AI ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß ‚úÖ")

                except Exception as e:
                    st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ AI: {e}")
                    st.session_state["gen_issues"] = ""
                    st.session_state["gen_findings"] = ""
                    st.session_state["gen_report"] = ""
    
    # --- MODIFIED: ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏°‡∏≤‡πÉ‡∏ä‡πâ Expander ‡∏ï‡∏≤‡∏°‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ ---
    st.subheader("‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å AI")

    with st.expander("1. ‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç", expanded=True):
        st.write(st.session_state.get('gen_issues', "‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏Å‡∏î '‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏à‡∏≤‡∏Å AI' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô"))

    with st.expander("2. ‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏û‡∏ö (‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÇ‡∏≠‡∏Å‡∏≤‡∏™)"):
        st.write(st.session_state.get('gen_findings', "‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"))

    with st.expander("3. ‡∏£‡πà‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö (Preview)"):
        st.write(st.session_state.get('gen_report', "‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"))


with tab_chatbot:
    st.subheader("üí¨ PA Chat - ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞ (RAG)")
    
    uploaded_files = st.file_uploader(
        "‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÉ‡∏´‡πâ AI (PDF, TXT, CSV) - ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå 'Doc'",
        type=['pdf', 'txt', 'csv'],
        accept_multiple_files=True
    )
    current_uploaded_file_names = {f.name for f in uploaded_files}
    if uploaded_files and st.session_state.get('last_uploaded_files') != current_uploaded_file_names:
        with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î..."):
            st.session_state.doc_context_uploaded, _ = process_documents(uploaded_files, 'uploaded', MAX_CHARS_LIMIT, len(st.session_state.get('doc_context_local', '')))
            st.session_state.last_uploaded_files = current_uploaded_file_names
            st.session_state.chatbot_messages.append({"role": "assistant", "content": "‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏£‡∏±‡∏ö"})
            st.rerun()
    elif not uploaded_files and st.session_state.doc_context_uploaded:
        st.session_state.doc_context_uploaded = ""
        st.session_state.last_uploaded_files = set()
        st.session_state.chatbot_messages.append({"role": "assistant", "content": "‡πÑ‡∏î‡πâ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏•‡πâ‡∏≤‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏≠‡∏≠‡∏Å‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏£‡∏±‡∏ö"})
        st.rerun()

    local_len = len(st.session_state.get('doc_context_local', ''))
    uploaded_len = len(st.session_state.get('doc_context_uploaded', ''))
    
    with st.expander("‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ö‡∏£‡∏¥‡∏ö‡∏ó (Context) ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ"):
        if local_len > 0:
            st.info(f"üíæ ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏à‡∏≤‡∏Å‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå 'Doc': {local_len:,} ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£")
        if uploaded_len > 0:
            st.info(f"üì§ ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î: {uploaded_len:,} ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£")
        st.success(f"‚úÖ ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {(local_len + uploaded_len):,} ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£ (‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î: {MAX_CHARS_LIMIT:,})")

    chat_container = st.container(height=500, border=True)
    with chat_container:
        for message in st.session_state.chatbot_messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

    if prompt := st.chat_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà...", key="chat_input_main"):
        st.session_state.chatbot_messages.append({"role": "user", "content": prompt})
        
        with chat_container:
            with st.chat_message("user"): st.markdown(prompt)
            with st.chat_message("assistant"):
                message_placeholder = st.empty()
                
                api_key = st.session_state.api_key_global
                if not api_key:
                    error_message = "‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: ‡πÑ‡∏°‡πà‡∏û‡∏ö API Key ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å API Key ‡∏ó‡∏µ‡πà Sidebar ‡∏î‡πâ‡∏≤‡∏ô‡∏ã‡πâ‡∏≤‡∏¢‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô"
                    message_placeholder.error(error_message)
                    st.session_state.chatbot_messages.append({"role": "assistant", "content": error_message})
                else:
                    try:
                        doc_context = st.session_state.get('doc_context_local', '') + st.session_state.get('doc_context_uploaded', '')
                        
                        system_prompt = f"""
‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢ AI ‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞ (Expert Assistant) ‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≠‡∏á‡πÅ‡∏´‡∏•‡πà‡∏á:
1.  **‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏†‡∏≤‡∏¢‡πÉ‡∏ô (Primary Source):** ‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå PDF ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå "Doc" ‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö ‡∏à‡∏á‡∏¢‡∏∂‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏™‡∏°‡∏≠
2.  **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏≠‡∏¥‡∏ô‡πÄ‡∏ó‡∏≠‡∏£‡πå‡πÄ‡∏ô‡πá‡∏ï (Secondary Source):** ‡∏´‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏†‡∏≤‡∏¢‡πÉ‡∏ô ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏ù‡∏ô (‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏ô‡∏≠‡∏¥‡∏ô‡πÄ‡∏ó‡∏≠‡∏£‡πå‡πÄ‡∏ô‡πá‡∏ï) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
**‡∏Å‡∏é‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö:**
- ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‡πÉ‡∏´‡πâ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡πÄ‡∏™‡∏°‡∏≠‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡πÅ‡∏´‡∏•‡πà‡∏á‡πÉ‡∏î (‡πÄ‡∏ä‡πà‡∏ô "‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ [‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå] ‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡πà‡∏≤..." ‡∏´‡∏£‡∏∑‡∏≠ "‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤" ‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡πà‡∏≤...) ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏ó‡∏£‡∏≤‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡πâ‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤ "‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤"
- ‡∏´‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏Ç‡∏±‡∏î‡πÅ‡∏¢‡πâ‡∏á‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡πÉ‡∏´‡πâ‡∏¢‡∏∂‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å‡πÅ‡∏•‡∏∞‡∏≠‡∏≤‡∏à‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏ñ‡∏∂‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡∏±‡∏î‡πÅ‡∏¢‡πâ‡∏á‡∏ô‡∏±‡πâ‡∏ô
- ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏±‡πâ‡∏á‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏ß‡πà‡∏≤ "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏ó‡∏±‡πâ‡∏á‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡∏ú‡∏°"
---
**‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏†‡∏≤‡∏¢‡πÉ‡∏ô:**
{doc_context}
---
‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô‡∏ô‡∏µ‡πâ ‡∏à‡∏á‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
"""
                        messages_for_api = [
                            {"role": "system", "content": system_prompt}
                        ] + st.session_state.chatbot_messages[-10:]

                        client = OpenAI(api_key=api_key, base_url="https://api.opentyphoon.ai/v1")
                        response_stream = client.chat.completions.create(
                            model="typhoon-v2.1-12b-instruct", 
                            messages=messages_for_api, 
                            temperature=0.5, 
                            max_tokens=3072, 
                            stream=True
                        )
                        response = message_placeholder.write_stream(response_stream)
                        st.session_state.chatbot_messages.append({"role": "assistant", "content": response})

                    except Exception as e:
                        error_message = f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏Ç‡∏ì‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô: {e}"
                        message_placeholder.error(error_message)
                        st.session_state.chatbot_messages.append({"role": "assistant", "content": error_message})
