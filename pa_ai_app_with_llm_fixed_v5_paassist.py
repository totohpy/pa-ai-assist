# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
from io import BytesIO
from datetime import datetime
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from openai import OpenAI
import os
import io
# *** ‡πÄ‡∏û‡∏¥‡πà‡∏° Imports ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö RAG Chatbot ***
from PyPDF2 import PdfReader
import glob
from io import StringIO

# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö RAG
MAX_CHARS_LIMIT = 100000 # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏ó‡∏µ‡πà 100,000 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏û‡∏à
st.set_page_config(page_title="Planning Studio (+ Issue Suggestions)", page_icon="üß≠", layout="wide")

# ----------------- Utility Functions ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö RAG Chatbot -----------------

def read_pdf_text_from_uploaded(uploaded_file):
    """Extracts text content from an uploaded PDF file."""
    try:
        reader = PdfReader(uploaded_file)
        text = ""
        for page in reader.pages:
            text += page.extract_text() or ""
        return text
    except Exception:
        return ""

def load_rag_context(uploaded_files_dict):
    """Loads text from uploaded files and stores in session state."""
    full_context = ""
    
    for file_name, file_data in uploaded_files_dict.items():
        if file_data["type"] == "pdf" or file_data["type"] == "txt":
            # file_data["content"] is already text, apply limit here for safety although it's applied during upload
            full_context += f"*** ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£: {file_name} ***\n{file_data['content'][:MAX_CHARS_LIMIT]}\n\n"
    
    st.session_state["rag_docs_context"] = full_context

    if len(full_context) > 0:
        st.success(f"‡πÇ‡∏´‡∏•‡∏î‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÅ‡∏•‡πâ‡∏ß (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß: {len(full_context)} ‡∏≠‡∏±‡∏Å‡∏Ç‡∏£‡∏∞)")
    else:
        st.info("‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏ö‡∏£‡∏¥‡∏ö‡∏ó RAG")

# ----------------- Session Init -----------------
def init_state():
    ss = st.session_state
    ss.setdefault("plan", {
        "plan_id": "PLN-" + datetime.now().strftime("%y%m%d-%H%M%S"),
        "plan_title": "",
        "program_name": "",
        "who": "", "what": "", "where": "", "when": "", "why": "", "how": "", "how_much": "", "whom": "",
        "objectives": "", "scope": "", "assumptions": "", "status": "Draft"
    })
    ss.setdefault("logic_items", pd.DataFrame(columns=["item_id","plan_id","type","description","metric","unit","target","source"]))
    ss.setdefault("methods", pd.DataFrame(columns=["method_id","plan_id","type","tool_ref","sampling","questions","linked_issue","data_source","frequency"]))
    ss.setdefault("kpis", pd.DataFrame(columns=["kpi_id","plan_id","level","name","formula","numerator","denominator","unit","baseline","target","frequency","data_source","quality_requirements"]))
    ss.setdefault("risks", pd.DataFrame(columns=["risk_id","plan_id","description","category","likelihood","impact","mitigation","hypothesis"]))
    ss.setdefault("audit_issues", pd.DataFrame(columns=["issue_id","plan_id","title","rationale","linked_kpi","proposed_methods","source_finding_id","issue_detail", "recommendation"]))
    ss.setdefault("gen_issues", "")
    ss.setdefault("gen_findings", "")
    ss.setdefault("gen_report", "")
    ss.setdefault("issue_results", pd.DataFrame())
    # ‡πÄ‡∏û‡∏¥‡πà‡∏° state ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡πà‡∏≤ Seed ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
    ss.setdefault("ref_seed", "") 
    ss.setdefault("issue_query_text", "")
    # *** ‡πÄ‡∏û‡∏¥‡πà‡∏° state ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Chatbot ***
    ss.setdefault("chatbot_messages", [])
    ss.setdefault("rag_docs_context", "")
    ss.setdefault("uploaded_files_content", {}) # Stores filename: {"type": "pdf"|"txt", "content": "...", "size": 1234}

def next_id(prefix, df, col):
    if df.empty: return f"{prefix}-001"
    nums = []
    for x in df[col]:
        try:
            nums.append(int(str(x).split("-")[-1]))
        except:
            pass
    n = max(nums) + 1 if nums else 1
    return f"{prefix}-{n:03d}"

def df_download_link(df: pd.DataFrame, filename: str, label: str):
    buf = BytesIO()
    df.to_csv(buf, index=False, encoding="utf-8-sig")
    st.download_button(label, data=buf.getvalue(), file_name=filename, mime="text/csv")

# ----------------- Findings Loader & Search -----------------
@st.cache_data(show_spinner=False)
def load_findings(uploaded=None):
    findings_df = pd.DataFrame()

    # 1. Try to load the pre-existing database file
    findings_db_path = "FindingsLibrary.csv"
    if os.path.exists(findings_db_path):
        try:
            findings_df = pd.read_csv(findings_db_path)
        except Exception as e:
            st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå FindingsLibrary.csv: {e}")
            findings_df = pd.DataFrame()

    # 2. If a new file is uploaded, combine it with the existing data
    if uploaded is not None:
        try:
            if uploaded.name.endswith('.csv'):
                uploaded_df = pd.read_csv(uploaded)
            elif uploaded.name.endswith(('.xlsx', '.xls')):
                xls = pd.ExcelFile(uploaded)
                if "Data" in xls.sheet_names:
                    uploaded_df = pd.read_excel(xls, sheet_name="Data")
                    st.success("‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏ä‡∏µ‡∏ï 'Data' ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
                else:
                    st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ä‡∏µ‡∏ï‡∏ä‡∏∑‡πà‡∏≠ 'Data' ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î ‡∏à‡∏∞‡∏≠‡πà‡∏≤‡∏ô‡∏à‡∏≤‡∏Å‡∏ä‡∏µ‡∏ï‡πÅ‡∏£‡∏Å‡πÅ‡∏ó‡∏ô")
                    uploaded_df = pd.read_excel(xls, sheet_name=0)

            if not uploaded_df.empty:
                findings_df = pd.concat([findings_df, uploaded_df], ignore_index=True)
                st.success(f"‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå '{uploaded.name}' ‡πÅ‡∏•‡∏∞‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ö‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏î‡∏¥‡∏°‡πÅ‡∏•‡πâ‡∏ß")
        except Exception as e:
            st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î: {e}")

    # 3. Clean and return the combined dataframe
    if not findings_df.empty:
        for c in ["issue_title","issue_detail","cause_detail","recommendation","program","unit"]:
            if c in findings_df.columns:
                findings_df[c] = findings_df[c].fillna("")
        if "year" in findings_df.columns:
            findings_df["year"] = pd.to_numeric(findings_df["year"], errors="coerce").fillna(0).astype(int)
        if "severity" in findings_df.columns:
            findings_df["severity"] = pd.to_numeric(findings_df["severity"], errors="coerce").fillna(3).clip(1,5).astype(int)

    return findings_df

@st.cache_resource(show_spinner=False)
def build_tfidf_index(findings_df: pd.DataFrame):
    texts = (findings_df["issue_title"].fillna("") + " " +
             findings_df["issue_detail"].fillna("") + " " +
             findings_df["cause_detail"].fillna("") + " " +
             findings_df["recommendation"].fillna(""))
    vec = TfidfVectorizer(max_features=20000, ngram_range=(1,2))
    X = vec.fit_transform(texts)
    return vec, X

def search_candidates(query_text, findings_df, vec, X, top_k=8):
    qv = vec.transform([query_text])
    sims = cosine_similarity(qv, X)[0]
    out = findings_df.copy()
    out["sim_score"] = sims
    if "year" in out.columns and out["year"].max() != out["year"].min():
        out["year_norm"] = (out["year"] - out["year"].min()) / (out["year"].max() - out["year"].min())
    else:
        out["year_norm"] = 0.0
    out["sev_norm"] = out.get("severity", 3) / 5
    out["score"] = out["sim_score"]*0.65 + out["sev_norm"]*0.25 + out["year_norm"]*0.10
    cols = [
        "finding_id","year","unit","program","issue_title","issue_detail",
        "cause_category","cause_detail","recommendation","outcomes_impact","severity","score"
    ]
    cols = [c for c in cols if c in out.columns] + ["sim_score"]
    return out.sort_values("score", ascending=False).head(top_k)[cols]
    
# Function to create an empty Excel template
def create_excel_template():
    df = pd.DataFrame(columns=[
        "finding_id", "issue_title", "unit", "program", "year", 
        "cause_category", "cause_detail", "issue_detail", "recommendation", 
        "outcomes_impact", "severity"
    ])
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df.to_excel(writer, index=False, sheet_name='FindingsLibrary')
    processed_data = output.getvalue()
    return processed_data

# ----------------- App UI -----------------
init_state()
plan = st.session_state["plan"]
logic_df = st.session_state["logic_items"]
methods_df = st.session_state["methods"]
kpis_df = st.session_state["kpis"]
risks_df = st.session_state["risks"]
audit_issues_df = st.session_state["audit_issues"]

st.title("üß≠ Planning Studio ‚Äì Performance Audit")

# ----------------- START: Custom CSS (User's preferred multi-color tabs) -----------------
st.markdown("""
<style>
/* ---- Global Font ---- */
body { font-family: 'Kanit', sans-serif; }

/* ---- Base Style for Tabs (Button Look) ---- */
button[data-baseweb="tab"] {
    border: 1px solid #007bff;
    border-radius: 8px;
    padding: 10px 15px;
    margin: 5px 5px 5px 0px;
    transition: background-color 0.3s, color 0.3s;
    font-weight: bold;
    color: #007bff !important;
    background-color: #ffffff;
    box-shadow: 1px 1px 3px rgba(0, 0, 0, 0.1);
    /* Remove default Streamlit tab line/highlight */
    border-bottom: none !important; 
    &::after { content: none !important; }
}
button[data-baseweb="tab"][aria-selected="true"] {
    box-shadow: 2px 2px 5px rgba(0,0,0,0.2);
}

/* ---- Group 1: 1-5 (Blue - Planning) ---- */
div[data-baseweb="tab-list"] button:nth-of-type(1),
div[data-baseweb="tab-list"] button:nth-of-type(2),
div[data-baseweb="tab-list"] button:nth-of-type(3),
div[data-baseweb="tab-list"] button:nth-of-type(4),
div[data-baseweb="tab-list"] button:nth-of-type(5) {
    border-color: #007bff;
    color: #007bff !important;
}
div[data-baseweb="tab-list"] button:nth-of-type(1)[aria-selected="true"],
div[data-baseweb="tab-list"] button:nth-of-type(2)[aria-selected="true"],
div[data-baseweb="tab-list"] button:nth-of-type(3)[aria-selected="true"],
div[data-baseweb="tab-list"] button:nth-of-type(4)[aria-selected="true"],
div[data-baseweb="tab-list"] button:nth-of-type(5)[aria-selected="true"] {
    background-color: #007bff;
    color: white !important;
}

/* ---- Group 2: 6-7 (Purple - Analysis/Review) ---- */
div[data-baseweb="tab-list"] button:nth-of-type(6),
div[data-baseweb="tab-list"] button:nth-of-type(7) {
    border-color: #6f42c1;
    color: #6f42c1 !important;
}
div[data-baseweb="tab-list"] button:nth-of-type(6)[aria-selected="true"],
div[data-baseweb="tab-list"] button:nth-of-type(7)[aria-selected="true"] {
    background-color: #6f42c1;
    color: white !important;
}

/* ---- Group 3: 8 (Gold - AI/Assist) ---- */
div[data-baseweb="tab-list"] button:nth-of-type(8) {
    border-color: #ffc107;
    color: #cc9900 !important;
    box-shadow: 0 0 5px rgba(255, 193, 7, 0.5);
}
div[data-baseweb="tab-list"] button:nth-of-type(8)[aria-selected="true"] {
    background-color: #ffc107;
    border-color: #ffc107;
    color: #333333 !important;
}

/* ---- Group 4: 9 (Green - Chatbot) ---- */
div[data-baseweb="tab-list"] button:nth-of-type(9) {
    border-color: #28a745;
    color: #28a745 !important;
    box-shadow: 0 0 5px rgba(40, 167, 69, 0.5);
}
div[data-baseweb="tab-list"] button:nth-of-type(9)[aria-selected="true"] {
    background-color: #28a745;
    border-color: #28a745;
    color: white !important;
}

/* ---- Container/Layout/Responsiveness ---- */
div[data-baseweb="tab-list"] { border-bottom: none !important; margin-bottom: 15px; flex-wrap: wrap; gap: 10px; }
@media (max-width: 768px) {
    .st-emotion-cache-18ni2cb, .st-emotion-cache-1jm69l4, [data-testid="stColumn"] {
        width: 100% !important;
        margin-bottom: 1rem;
    }
}

/* ---- Headers ---- */
h4 { color: #007bff !important; border-bottom: 2px solid #e0e0e0; padding-bottom: 5px; }
</style>
""", unsafe_allow_html=True)
# ----------------- END: Custom CSS -----------------

# ----------------- Tab Definitions -----------------
# **‡πÄ‡∏û‡∏¥‡πà‡∏° tab_chatbot ‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤**
tab_plan, tab_logic, tab_method, tab_kpi, tab_risk, tab_issue, tab_preview, tab_assist, tab_chatbot = st.tabs([
    "1. ‡∏£‡∏∞‡∏ö‡∏∏ ‡πÅ‡∏ú‡∏ô & 6W2H", 
    "2. ‡∏£‡∏∞‡∏ö‡∏∏ Logic Model", 
    "3. ‡∏£‡∏∞‡∏ö‡∏∏ Methods", 
    "4. ‡∏£‡∏∞‡∏ö‡∏∏ KPIs", 
    "5. ‡∏£‡∏∞‡∏ö‡∏∏ Risks", 
    "6. ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏°‡∏≤", 
    "7. ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Preview)", 
    "8. ‡πÉ‡∏´‡πâ PA Assist ‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö ‚ú®‚ú®",
    "9. RAG Chatbot üí¨" # New tab
]) 

# ----------------- Tab 1: ‡∏£‡∏∞‡∏ö‡∏∏ ‡πÅ‡∏ú‡∏ô & 6W2H -----------------
with tab_plan:
    st.subheader("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ú‡∏ô (Plan) - ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏∞‡∏ö‡∏∏‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
    with st.container(border=True):
        c1, c2, c3 = st.columns([2,2,1])
        with c1:
            plan["plan_title"] = st.text_input("‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏ú‡∏ô/‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ï‡∏£‡∏ß‡∏à", plan["plan_title"])
            plan["program_name"] = st.text_input("‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£/‡πÅ‡∏ú‡∏ô‡∏á‡∏≤‡∏ô", plan["program_name"])
            plan["objectives"] = st.text_area("‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à", plan["objectives"])
        with c2:
            plan["scope"] = st.text_area("‡∏Ç‡∏≠‡∏ö‡πÄ‡∏Ç‡∏ï‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à", plan["scope"])
            plan["assumptions"] = st.text_area("‡∏™‡∏°‡∏°‡∏∏‡∏ï‡∏¥‡∏ê‡∏≤‡∏ô/‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", plan["assumptions"])
        with c3:
            st.text_input("Plan ID", plan["plan_id"], disabled=True)
            plan["status"] = st.selectbox("‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞", ["Draft","Published"], index=0)

    st.divider()
    st.subheader("‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö (6W2H)")

    with st.container(border=True):
        st.markdown("##### üöÄ ‡∏™‡∏£‡πâ‡∏≤‡∏á 6W2H ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏î‡πâ‡∏ß‡∏¢ AI")
        st.write("‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÅ‡∏•‡πâ‡∏ß‡∏ô‡∏≥‡∏°‡∏≤‡∏ß‡∏≤‡∏á‡πÉ‡∏ô‡∏ä‡πà‡∏≠‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ")
        uploaded_text = st.text_area("‡∏£‡∏∞‡∏ö‡∏∏‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ AI ‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏£‡∏∏‡∏õ 6W2H", height=200, key="uploaded_text")
        st.markdown("üí° **‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ API Key?** ‡∏Ñ‡∏•‡∏¥‡∏Å [‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà](https://playground.opentyphoon.ai/settings/api-key) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ö key ‡∏ü‡∏£‡∏µ!")
        api_key_6w2h = st.text_input("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å API Key ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£ AI:", type="password", key="api_key_6w2h")

        if st.button("üöÄ ‡∏™‡∏£‡πâ‡∏≤‡∏á 6W2H ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°", type="primary", key="6w2h_button"):
            if not uploaded_text:
                st.error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ß‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏ô‡∏ä‡πà‡∏≠‡∏á‡∏Å‡πà‡∏≠‡∏ô")
            elif not api_key_6w2h:
                st.error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å API Key ‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
            else:
                with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•..."):
                    try:
                        user_prompt = f"""
‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏•‡∏∞‡πÅ‡∏¢‡∏Å‡πÅ‡∏¢‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô 6W2H ‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πà Who, Whom, What, Where, When, Why, How, ‡πÅ‡∏•‡∏∞ How much ‡πÇ‡∏î‡∏¢‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö key-value ‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°:
---
{uploaded_text}
---
‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£:
Who: [‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°]
Whom: [‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°]
What: [‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°]
Where: [‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°]
When: [‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°]
Why: [‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°]
How: [‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°]
How Much: [‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°]
"""
                        client = OpenAI(
                            api_key=api_key_6w2h,
                            base_url="https://api.opentyphoon.ai/v1"
                        )
                        response = client.chat.completions.create(
                            model="typhoon-v2.1-12b-instruct",
                            messages=[{"role": "user", "content": user_prompt}],
                            temperature=0.7,
                            max_tokens=1024,
                            top_p=0.9,
                        )
                        llm_output = response.choices[0].message.content
                        
                        with st.expander("‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å AI"):
                            st.write(llm_output)

                        lines = llm_output.strip().split('\n')
                        for line in lines:
                            if ':' in line:
                                key, value = line.split(':', 1)
                                normalized_key = key.strip().lower().replace(' ', '_')
                                value = value.strip()
                                if normalized_key == 'how_much': st.session_state.plan['how_much'] = value
                                elif normalized_key == 'whom': st.session_state.plan['whom'] = value
                                elif normalized_key == 'who': st.session_state.plan['who'] = value
                                elif normalized_key == 'what': st.session_state.plan['what'] = value
                                elif normalized_key == 'where': st.session_state.plan['where'] = value
                                elif normalized_key == 'when': st.session_state.plan['when'] = value
                                elif normalized_key == 'why': st.session_state.plan['why'] = value
                                elif normalized_key == 'how': st.session_state.plan['how'] = value
                        st.success("‡∏™‡∏£‡πâ‡∏≤‡∏á 6W2H ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß! ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡πÑ‡∏õ‡∏ß‡∏≤‡∏á‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á")
                        st.balloons()
                    except Exception as e:
                        error_type = type(e).__name__
                        if error_type in ["AuthenticationError", "RateLimitError"]:
                            st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ API: ({error_type}) ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö API Key ‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô (Rate Limit) ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì\n‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î: {e}")
                        else:
                            st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏Ç‡∏ì‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô: ({error_type}) ‡πÇ‡∏õ‡∏£‡∏î‡∏•‡∏≠‡∏á‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á\n‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î: {e}")
            
    st.markdown("##### ‚≠ê‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏∞‡∏ö‡∏∏‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏≥‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•")
    with st.container(border=True):
        cc1, cc2, cc3 = st.columns(3)
        with cc1:
            st.session_state.plan["who"] = st.text_input("Who (‡πÉ‡∏Ñ‡∏£)", value=st.session_state.plan["who"], key="who_input")
            st.session_state.plan["whom"] = st.text_input("Whom (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏Ñ‡∏£)", value=st.session_state.plan["whom"], key="whom_input")
            st.session_state.plan["what"] = st.text_input("What (‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£)", value=st.session_state.plan["what"], key="what_input")
            st.session_state.plan["where"] = st.text_input("Where (‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô)", value=st.session_state.plan["where"], key="where_input")
        with cc2:
            st.session_state.plan["when"] = st.text_input("When (‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÉ‡∏î)", value=st.session_state.plan["when"], key="when_input")
            st.session_state.plan["why"] = st.text_area("Why (‡∏ó‡∏≥‡πÑ‡∏°)", value=st.session_state.plan["why"], key="why_input")
        with cc3:
            st.session_state.plan["how"] = st.text_area("How (‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£)", value=st.session_state.plan["how"], key="how_input")
            st.session_state.plan["how_much"] = st.text_input("How much (‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏£)", value=st.session_state.plan["how_much"], key="how_much_input")

# ----------------- Tab 2: Logic Model -----------------
with tab_logic:
    st.subheader("‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ Logic Model / Theory of Change")
    # ... (Code for Tab 2 content remains the same)
    
    # Logic Item Addition Form
    with st.form("logic_form", clear_on_submit=True, border=True):
        st.markdown("##### ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ Logic Model")
        c1, c2 = st.columns([1,3])
        with c1:
            item_type = st.selectbox("‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó", ["Input","Activity","Output","Outcome","Impact"], key="logic_type")
        with c2:
            description = st.text_input("‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î", key="logic_desc")
        
        c3, c4, c5 = st.columns(3)
        with c3:
            metric = st.text_input("‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î", key="logic_metric")
        with c4:
            unit = st.text_input("‡∏´‡∏ô‡πà‡∏ß‡∏¢", key="logic_unit")
        with c5:
            target = st.text_input("‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢", key="logic_target")
        
        source = st.text_input("‡πÅ‡∏´‡∏•‡πà‡∏á‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á", key="logic_source")
        
        submitted = st.form_submit_button("‚ûï ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        if submitted and description:
            new_id = next_id(item_type[0].upper(), logic_df, "item_id")
            new_row = {
                "item_id": new_id,
                "plan_id": plan["plan_id"],
                "type": item_type,
                "description": description,
                "metric": metric,
                "unit": unit,
                "target": target,
                "source": source
            }
            st.session_state["logic_items"] = pd.concat([logic_df, pd.DataFrame([new_row])], ignore_index=True)
            st.success(f"‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ {item_type} ID: {new_id} ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
        elif submitted and not description:
            st.error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î")

    st.divider()

    # Logic Item Display and Editor
    st.markdown("##### ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ Logic Model")
    if logic_df.empty:
        st.info("‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ Logic Model")
    else:
        # Re-order and display the dataframe
        display_df = logic_df[["item_id", "type", "description", "metric", "unit", "target", "source"]]
        
        # In-line editor
        edited_df = st.data_editor(
            display_df,
            column_config={
                "item_id": st.column_config.TextColumn("ID", disabled=True),
                "type": st.column_config.SelectboxColumn("‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó", options=["Input","Activity","Output","Outcome","Impact"]),
                "description": st.column_config.TextColumn("‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î", required=True),
                "metric": st.column_config.TextColumn("‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î"),
                "unit": st.column_config.TextColumn("‡∏´‡∏ô‡πà‡∏ß‡∏¢"),
                "target": st.column_config.TextColumn("‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢"),
                "source": st.column_config.TextColumn("‡πÅ‡∏´‡∏•‡πà‡∏á‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á")
            },
            hide_index=True,
            num_rows="dynamic"
        )
        
        # Save button for edited data
        if st.button("üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç Logic Model"):
            # Ensure required column is present before merge
            if "plan_id" not in edited_df.columns:
                 edited_df["plan_id"] = plan["plan_id"]
            if "item_id" not in edited_df.columns:
                 edited_df["item_id"] = logic_df["item_id"] # Re-attach IDs if they somehow disappeared
            
            # Merge back with the original columns (like plan_id)
            final_df = pd.merge(logic_df.drop(columns=["type", "description", "metric", "unit", "target", "source"], errors='ignore'),
                                edited_df,
                                on="item_id",
                                how="right",
                                suffixes=('_old', ''))

            # Re-index the IDs for new rows added via dynamic rows
            for index, row in final_df.iterrows():
                if not pd.isna(row["type"]) and not str(row["item_id"]).startswith(row["type"][0].upper()):
                    final_df.loc[index, "item_id"] = next_id(row["type"][0].upper(), final_df, "item_id")
                    
            st.session_state["logic_items"] = final_df.dropna(subset=["description"]).reset_index(drop=True)
            st.success("‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Logic Model ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")

# ----------------- Tab 3: ‡∏£‡∏∞‡∏ö‡∏∏ Methods -----------------
with tab_method:
    st.subheader("‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö (Audit Methods)")
    # ... (Code for Tab 3 content remains the same)
    
    # Method Addition Form
    with st.form("method_form", clear_on_submit=True, border=True):
        st.markdown("##### ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö")
        c1, c2 = st.columns([1,3])
        with c1:
            method_type = st.selectbox("‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó", ["Observation","Interview","Survey","Document Review","Data Analysis","Simulation/Test"], key="method_type")
        with c2:
            tool_ref = st.text_input("‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠/‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á (‡πÄ‡∏ä‡πà‡∏ô ‡πÅ‡∏ö‡∏ö‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°, ‡∏£‡∏´‡∏±‡∏™‡πÇ‡∏Ñ‡πâ‡∏î)", key="method_tool")
            
        questions = st.text_area("‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°/‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç", key="method_questions", height=100)
        
        c3, c4, c5 = st.columns(3)
        with c3:
            sampling = st.text_input("‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏™‡∏∏‡πà‡∏°‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á", key="method_sampling")
        with c4:
            data_source = st.text_input("‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", key="method_source")
        with c5:
            frequency = st.text_input("‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà/‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤", key="method_frequency")
        
        linked_issue = st.multiselect(
            "‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á‡∏Å‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö (Issue)", 
            options=audit_issues_df["issue_id"].tolist(),
            key="method_linked_issue"
        )
        
        submitted = st.form_submit_button("‚ûï ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        if submitted and questions:
            new_id = next_id("M", methods_df, "method_id")
            new_row = {
                "method_id": new_id,
                "plan_id": plan["plan_id"],
                "type": method_type,
                "tool_ref": tool_ref,
                "sampling": sampling,
                "questions": questions,
                "linked_issue": ", ".join(linked_issue),
                "data_source": data_source,
                "frequency": frequency
            }
            st.session_state["methods"] = pd.concat([methods_df, pd.DataFrame([new_row])], ignore_index=True)
            st.success(f"‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ Method ID: {new_id} ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
        elif submitted and not questions:
            st.error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°/‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç")
    
    st.divider()

    # Method Display and Editor
    st.markdown("##### ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö")
    if methods_df.empty:
        st.info("‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö")
    else:
        display_df = methods_df[["method_id", "type", "tool_ref", "questions", "sampling", "data_source", "frequency", "linked_issue"]]
        edited_df = st.data_editor(
            display_df,
            column_config={
                "method_id": st.column_config.TextColumn("ID", disabled=True),
                "type": st.column_config.SelectboxColumn("‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó", options=["Observation","Interview","Survey","Document Review","Data Analysis","Simulation/Test"]),
                "tool_ref": st.column_config.TextColumn("‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠/‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á"),
                "questions": st.column_config.TextColumn("‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°/‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç", required=True),
                "sampling": st.column_config.TextColumn("‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏™‡∏∏‡πà‡∏°‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á"),
                "data_source": st.column_config.TextColumn("‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"),
                "frequency": st.column_config.TextColumn("‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà/‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤"),
                "linked_issue": st.column_config.TextColumn("‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á‡∏Å‡∏±‡∏ö Issue ID")
            },
            hide_index=True,
            num_rows="dynamic"
        )
        
        if st.button("üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç Methods"):
             # Simple merge back to preserve original plan_id
            final_df = pd.merge(methods_df.drop(columns=["type", "tool_ref", "questions", "sampling", "linked_issue", "data_source", "frequency"], errors='ignore'),
                                edited_df,
                                on="method_id",
                                how="right",
                                suffixes=('_old', ''))

            st.session_state["methods"] = final_df.dropna(subset=["questions"]).reset_index(drop=True)
            st.success("‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Methods ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")

# ----------------- Tab 4: ‡∏£‡∏∞‡∏ö‡∏∏ KPIs -----------------
with tab_kpi:
    st.subheader("‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î (Key Performance Indicators - KPIs)")
    # ... (Code for Tab 4 content remains the same)
    
    # KPI Addition Form
    with st.form("kpi_form", clear_on_submit=True, border=True):
        st.markdown("##### ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î")
        c1, c2 = st.columns([1,3])
        with c1:
            level = st.selectbox("‡∏£‡∏∞‡∏î‡∏±‡∏ö", ["Process","Output","Outcome","Impact"], key="kpi_level")
        with c2:
            # *** ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡∏•‡∏ö required=True ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å st.text_input ***
            name = st.text_input("‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î", key="kpi_name") 
            
        c3, c4 = st.columns(2)
        with c3:
            numerator = st.text_input("‡∏ï‡∏±‡∏ß‡πÄ‡∏®‡∏© (Numerator)", key="kpi_numerator")
            denominator = st.text_input("‡∏ï‡∏±‡∏ß‡∏™‡πà‡∏ß‡∏ô (Denominator)", key="kpi_denominator")
            formula = st.text_input("‡∏™‡∏π‡∏ï‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì", value=f"({numerator}) / ({denominator})" if numerator and denominator else "", key="kpi_formula")
        with c4:
            unit = st.text_input("‡∏´‡∏ô‡πà‡∏ß‡∏¢", key="kpi_unit")
            baseline = st.text_input("‡∏Ñ‡πà‡∏≤‡∏ê‡∏≤‡∏ô (Baseline)", key="kpi_baseline")
            target = st.text_input("‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ (Target)", key="kpi_target")
            
        c5, c6 = st.columns(2)
        with c5:
            frequency = st.text_input("‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏±‡∏î", key="kpi_frequency")
        with c6:
            data_source = st.text_input("‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", key="kpi_data_source")

        quality_requirements = st.text_area("‡∏Ç‡πâ‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏î‡πâ‡∏≤‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", key="kpi_quality", height=80)
        
        submitted = st.form_submit_button("‚ûï ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        if submitted and name:
            new_id = next_id("K", kpis_df, "kpi_id")
            new_row = {
                "kpi_id": new_id,
                "plan_id": plan["plan_id"],
                "level": level,
                "name": name,
                "formula": formula,
                "numerator": numerator,
                "denominator": denominator,
                "unit": unit,
                "baseline": baseline,
                "target": target,
                "frequency": frequency,
                "data_source": data_source,
                "quality_requirements": quality_requirements
            }
            st.session_state["kpis"] = pd.concat([kpis_df, pd.DataFrame([new_row])], ignore_index=True)
            st.success(f"‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ KPI ID: {new_id} ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
        elif submitted and not name:
            st.error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î")

    st.divider()

    # KPI Display and Editor
    st.markdown("##### ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î")
    if kpis_df.empty:
        st.info("‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î")
    else:
        # Simplified display columns
        display_cols = ["kpi_id", "level", "name", "formula", "unit", "target", "data_source"]
        display_df = kpis_df[[c for c in display_cols if c in kpis_df.columns]].copy()
        
        edited_df = st.data_editor(
            display_df,
            column_config={
                "kpi_id": st.column_config.TextColumn("ID", disabled=True),
                "level": st.column_config.SelectboxColumn("‡∏£‡∏∞‡∏î‡∏±‡∏ö", options=["Process","Output","Outcome","Impact"]),
                "name": st.column_config.TextColumn("‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î", required=True),
                "formula": st.column_config.TextColumn("‡∏™‡∏π‡∏ï‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì"),
                "unit": st.column_config.TextColumn("‡∏´‡∏ô‡πà‡∏ß‡∏¢"),
                "target": st.column_config.TextColumn("‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢"),
                "data_source": st.column_config.TextColumn("‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
            },
            hide_index=True,
            num_rows="dynamic"
        )
        
        if st.button("üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç KPIs"):
            # Ensure all original columns are preserved during merge
            kpi_cols_to_drop = [c for c in kpis_df.columns if c not in edited_df.columns]
            final_df = pd.merge(kpis_df.drop(columns=kpi_cols_to_drop, errors='ignore'),
                                edited_df,
                                on="kpi_id",
                                how="right",
                                suffixes=('_old', ''))

            # Re-index the IDs for new rows added via dynamic rows if necessary
            # (Assuming new rows won't have kpi_id, so they will be NaN or empty string)
            st.session_state["kpis"] = final_df.dropna(subset=["name"]).reset_index(drop=True)
            st.success("‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å KPIs ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")

# ----------------- Tab 5: ‡∏£‡∏∞‡∏ö‡∏∏ Risks -----------------
with tab_risk:
    st.subheader("‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á (Audit Risks)")
    # ... (Code for Tab 5 content remains the same)
    
    # Risk Addition Form
    with st.form("risk_form", clear_on_submit=True, border=True):
        st.markdown("##### ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á")
        description = st.text_area("‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á/‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô", key="risk_desc", height=80, required=True)
        
        c1, c2, c3 = st.columns(3)
        with c1:
            category = st.text_input("‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á", key="risk_cat")
        with c2:
            likelihood = st.slider("‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡πÄ‡∏Å‡∏¥‡∏î (Likelihood)", 1, 5, 3, key="risk_like")
        with c3:
            impact = st.slider("‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö (Impact)", 1, 5, 3, key="risk_impact")
            
        mitigation = st.text_area("‡∏°‡∏≤‡∏ï‡∏£‡∏Å‡∏≤‡∏£/‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á", key="risk_mitigation", height=80)
        hypothesis = st.text_area("‡∏™‡∏°‡∏°‡∏∏‡∏ï‡∏¥‡∏ê‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö (Audit Hypothesis)", key="risk_hypothesis", height=80)
        
        submitted = st.form_submit_button("‚ûï ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        if submitted and description:
            new_id = next_id("R", risks_df, "risk_id")
            new_row = {
                "risk_id": new_id,
                "plan_id": plan["plan_id"],
                "description": description,
                "category": category,
                "likelihood": likelihood,
                "impact": impact,
                "mitigation": mitigation,
                "hypothesis": hypothesis
            }
            st.session_state["risks"] = pd.concat([risks_df, pd.DataFrame([new_row])], ignore_index=True)
            st.success(f"‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ Risk ID: {new_id} ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
        elif submitted and not description:
            st.error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á")

    st.divider()

    # Risk Display and Editor
    st.markdown("##### ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á")
    if risks_df.empty:
        st.info("‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á")
    else:
        # Calculate Risk Score (L x I)
        display_df = risks_df.copy()
        display_df["Score"] = display_df["likelihood"] * display_df["impact"]
        display_df = display_df[["risk_id", "description", "category", "likelihood", "impact", "Score", "mitigation", "hypothesis"]]
        
        edited_df = st.data_editor(
            display_df,
            column_config={
                "risk_id": st.column_config.TextColumn("ID", disabled=True),
                "description": st.column_config.TextColumn("‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á", required=True),
                "category": st.column_config.TextColumn("‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó"),
                "likelihood": st.column_config.NumberColumn("‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡πÄ‡∏Å‡∏¥‡∏î (1-5)", min_value=1, max_value=5, format="%d"),
                "impact": st.column_config.NumberColumn("‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö (1-5)", min_value=1, max_value=5, format="%d"),
                "Score": st.column_config.NumberColumn("‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á", disabled=True),
                "mitigation": st.column_config.TextColumn("‡∏°‡∏≤‡∏ï‡∏£‡∏Å‡∏≤‡∏£‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á"),
                "hypothesis": st.column_config.TextColumn("‡∏™‡∏°‡∏°‡∏∏‡∏ï‡∏¥‡∏ê‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö"),
            },
            hide_index=True,
            num_rows="dynamic"
        )
        
        if st.button("üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç Risks"):
             # Simple merge back to preserve original plan_id
            risks_cols_to_drop = [c for c in risks_df.columns if c not in edited_df.columns]
            final_df = pd.merge(risks_df.drop(columns=risks_cols_to_drop, errors='ignore'),
                                edited_df,
                                on="risk_id",
                                how="right",
                                suffixes=('_old', ''))
            
            # Re-index the IDs for new rows added via dynamic rows if necessary
            st.session_state["risks"] = final_df.dropna(subset=["description"]).drop(columns=["Score"], errors='ignore').reset_index(drop=True)
            st.success("‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Risks ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")

# ----------------- Tab 6: ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏°‡∏≤ -----------------
with tab_issue:
    st.subheader("‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á (Prior Findings Search)")

    with st.container(border=True):
        st.markdown("##### ‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö")
        
        findings_df = load_findings()
        
        if not findings_df.empty:
            st.info(f"‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏°‡∏µ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô {len(findings_df)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
            
            c1, c2 = st.columns([1,1])
            with c1:
                uploaded_file = st.file_uploader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå CSV/Excel (‡∏ä‡∏µ‡∏ï‡∏ä‡∏∑‡πà‡∏≠ 'Data') ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", type=["csv", "xlsx", "xls"])
                if uploaded_file:
                    findings_df = load_findings(uploaded=uploaded_file) # Re-load with the new file
            with c2:
                template_data = create_excel_template()
                st.download_button(
                    label="‚¨áÔ∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î Template Excel",
                    data=template_data,
                    file_name="PriorFindingsTemplate.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
                
            # Search input
            st.markdown("##### üîç ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö")
            issue_query = st.text_area(
                "‡πÉ‡∏™‡πà‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ (‡πÄ‡∏ä‡πà‡∏ô ‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£, ‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏ô‡πÉ‡∏à, ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏û‡∏ö)", 
                height=100, 
                value=st.session_state.get("issue_query_text", "")
            )
            st.session_state["issue_query_text"] = issue_query # Update state for persistence

            if st.button("üîé ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö", type="primary", use_container_width=True):
                if issue_query and not findings_df.empty:
                    try:
                        vec, X = build_tfidf_index(findings_df)
                        results_df = search_candidates(issue_query, findings_df, vec, X, top_k=10)
                        st.session_state["issue_results"] = results_df
                        st.success("‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")
                    except Exception as e:
                        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤: {e}")
                else:
                    st.warning("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ ‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡πÅ‡∏•‡πâ‡∏ß")
        else:
            st.error("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå")

    st.divider()

    st.markdown("##### ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤")
    results_df = st.session_state.get("issue_results", pd.DataFrame())

    if not results_df.empty:
        # Display search results
        st.dataframe(
            results_df,
            column_config={
                "finding_id": "ID",
                "year": "‡∏õ‡∏µ",
                "unit": "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô",
                "program": "‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£/‡πÅ‡∏ú‡∏ô‡∏á‡∏≤‡∏ô",
                "issue_title": "‡∏ä‡∏∑‡πà‡∏≠‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö",
                "issue_detail": "‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏õ‡∏±‡∏ç‡∏´‡∏≤",
                "cause_category": "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏",
                "cause_detail": "‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏",
                "recommendation": "‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞",
                "outcomes_impact": "‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå/‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö",
                "severity": "‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á (1-5)",
                "score": st.column_config.NumberColumn("‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏£‡∏ß‡∏°", format="%.3f"),
                "sim_score": st.column_config.NumberColumn("‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢", format="%.3f"),
            },
            hide_index=True,
            use_container_width=True
        )

        st.markdown("##### üìå ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö (Issue) ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏ó‡∏µ‡πà‡∏û‡∏ö")
        
        # User selection to create a new issue
        selected_id = st.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å ID ‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÑ‡∏õ‡∏™‡∏£‡πâ‡∏≤‡∏á Issue", options=[""] + results_df["finding_id"].tolist())
        
        if selected_id:
            selected_finding = results_df[results_df["finding_id"] == selected_id].iloc[0]
            
            with st.form("issue_creation_form", clear_on_submit=False, border=True):
                st.write(f"**‡∏ô‡∏≥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å ID: {selected_id}**")
                
                title = st.text_input("‡∏ä‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö (Issue Title)", value=selected_finding["issue_title"], key="new_issue_title")
                rationale = st.text_area("‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•/‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤", value=f"‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö ID: {selected_id} ‡∏Ç‡∏≠‡∏á‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô {selected_finding['unit']} ‡πÉ‡∏ô‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£ {selected_finding['program']} ‡∏õ‡∏µ {selected_finding['year']} ‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ß‡πà‡∏≤ {selected_finding['issue_title']}", key="new_issue_rationale")
                issue_detail = st.text_area("‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏õ‡∏±‡∏ç‡∏´‡∏≤ (‡∏ô‡∏≥‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö)", value=selected_finding.get("issue_detail", ""), key="new_issue_detail")
                recommendation = st.text_area("‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô (‡∏ô‡∏≥‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö)", value=selected_finding.get("recommendation", ""), key="new_issue_recommendation")

                linked_kpi = st.multiselect(
                    "‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á‡∏Å‡∏±‡∏ö KPI ID", 
                    options=kpis_df["kpi_id"].tolist(),
                    key="new_issue_linked_kpi"
                )
                
                # Automatically suggest methods based on current plan methods
                all_methods = methods_df["method_id"].tolist()
                proposed_methods = st.multiselect(
                    "‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏™‡∏ô‡∏≠", 
                    options=all_methods,
                    default=all_methods, # Default to all current methods for suggestion
                    key="new_issue_proposed_methods"
                )

                issue_submitted = st.form_submit_button("‚ûï ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö (Issue)")
                
                if issue_submitted and title:
                    new_id = next_id("I", audit_issues_df, "issue_id")
                    new_issue_row = {
                        "issue_id": new_id,
                        "plan_id": plan["plan_id"],
                        "title": title,
                        "rationale": rationale,
                        "linked_kpi": ", ".join(linked_kpi),
                        "proposed_methods": ", ".join(proposed_methods),
                        "source_finding_id": selected_id,
                        "issue_detail": issue_detail,
                        "recommendation": recommendation
                    }
                    st.session_state["audit_issues"] = pd.concat([audit_issues_df, pd.DataFrame([new_issue_row])], ignore_index=True)
                    st.success(f"‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Issue ID: {new_id} ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
                elif issue_submitted and not title:
                    st.error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö")
    else:
        st.info("‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤")
        
    st.divider()

    st.markdown("##### ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö (Audit Issues)")
    # Issue Display and Editor
    if audit_issues_df.empty:
        st.info("‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å")
    else:
        display_df = audit_issues_df[["issue_id", "title", "rationale", "linked_kpi", "proposed_methods", "source_finding_id"]]
        
        edited_df = st.data_editor(
            display_df,
            column_config={
                "issue_id": st.column_config.TextColumn("ID", disabled=True),
                "title": st.column_config.TextColumn("‡∏ä‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö", required=True),
                "rationale": st.column_config.TextColumn("‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•/‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤"),
                "linked_kpi": st.column_config.TextColumn("‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á KPI ID"),
                "proposed_methods": st.column_config.TextColumn("‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏™‡∏ô‡∏≠"),
                "source_finding_id": st.column_config.TextColumn("‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡πÄ‡∏î‡∏¥‡∏°"),
            },
            hide_index=True,
            num_rows="dynamic"
        )
        
        if st.button("üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç Issues"):
            issues_cols_to_drop = [c for c in audit_issues_df.columns if c not in edited_df.columns]
            final_df = pd.merge(audit_issues_df.drop(columns=issues_cols_to_drop, errors='ignore'),
                                edited_df,
                                on="issue_id",
                                how="right",
                                suffixes=('_old', ''))

            st.session_state["audit_issues"] = final_df.dropna(subset=["title"]).reset_index(drop=True)
            st.success("‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Issues ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
            
# ----------------- Tab 7: ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Preview) -----------------
with tab_preview:
    st.subheader("‡∏™‡∏£‡∏∏‡∏õ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö")
    
    st.markdown("#### 1. ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ú‡∏ô‡πÅ‡∏•‡∏∞ 6W2H")
    st.dataframe(pd.DataFrame(plan, index=["Detail"]).T, use_container_width=True)
    
    st.markdown("#### 2. Logic Model")
    if not logic_df.empty:
        st.dataframe(logic_df.drop(columns=["plan_id"], errors='ignore'), use_container_width=True)
    else: st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Logic Model")
    
    st.markdown("#### 3. KPIs")
    if not kpis_df.empty:
        st.dataframe(kpis_df.drop(columns=["plan_id", "numerator", "denominator", "baseline", "quality_requirements"], errors='ignore'), use_container_width=True)
    else: st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• KPI")
    
    st.markdown("#### 4. Risks & Hypothesis")
    if not risks_df.empty:
        display_risks = risks_df.copy()
        display_risks["Score"] = display_risks["likelihood"] * display_risks["impact"]
        st.dataframe(display_risks.drop(columns=["plan_id"], errors='ignore'), use_container_width=True)
    else: st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Risks")
    
    st.markdown("#### 5. Audit Issues")
    if not audit_issues_df.empty:
        st.dataframe(audit_issues_df.drop(columns=["plan_id", "issue_detail", "recommendation"], errors='ignore'), use_container_width=True)
    else: st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Issues")
    
    st.markdown("#### 6. Audit Methods")
    if not methods_df.empty:
        st.dataframe(methods_df.drop(columns=["plan_id"], errors='ignore'), use_container_width=True)
    else: st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Methods")

    st.divider()
    
    c1, c2, c3 = st.columns(3)
    with c1:
        df_download_link(st.session_state["logic_items"], "logic_model.csv", "‚¨áÔ∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î Logic Model (CSV)")
    with c2:
        df_download_link(st.session_state["kpis"], "kpis.csv", "‚¨áÔ∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î KPIs (CSV)")
    with c3:
        df_download_link(st.session_state["audit_issues"], "audit_issues.csv", "‚¨áÔ∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î Issues (CSV)")

# ----------------- Tab 8: ‡πÉ‡∏´‡πâ PA Assist ‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö -----------------
with tab_assist:
    st.subheader("ü§ñ PA Assist - ‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏û‡∏ö")
    
    with st.container(border=True):
        st.markdown("##### ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á (Context) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI")
        
        # Combine all relevant plan data into a single context string
        context_parts = []
        context_parts.append(f"Plan ID: {plan['plan_id']}")
        context_parts.append(f"‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏ú‡∏ô/‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á: {plan['plan_title']}")
        context_parts.append(f"‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£/‡πÅ‡∏ú‡∏ô‡∏á‡∏≤‡∏ô: {plan['program_name']}")
        context_parts.append(f"‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå: {plan['objectives']}")
        context_parts.append(f"‡∏Ç‡∏≠‡∏ö‡πÄ‡∏Ç‡∏ï: {plan['scope']}")
        context_parts.append(f"‡∏™‡∏°‡∏°‡∏∏‡∏ï‡∏¥‡∏ê‡∏≤‡∏ô/‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î: {plan['assumptions']}")
        context_parts.append("\n--- 6W2H ---")
        context_parts.append(f"Who (‡πÉ‡∏Ñ‡∏£): {plan['who']}")
        context_parts.append(f"Whom (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏Ñ‡∏£): {plan['whom']}")
        context_parts.append(f"What (‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£): {plan['what']}")
        context_parts.append(f"Where (‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô): {plan['where']}")
        context_parts.append(f"When (‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÉ‡∏î): {plan['when']}")
        context_parts.append(f"Why (‡∏ó‡∏≥‡πÑ‡∏°): {plan['why']}")
        context_parts.append(f"How (‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£): {plan['how']}")
        context_parts.append(f"How much (‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏£): {plan['how_much']}")
        
        if not logic_df.empty:
            context_parts.append("\n--- Logic Model ---")
            context_parts.append(logic_df[["type", "description", "target"]].to_markdown(index=False))
            
        if not kpis_df.empty:
            context_parts.append("\n--- KPIs ---")
            context_parts.append(kpis_df[["name", "level", "formula", "target", "data_source"]].to_markdown(index=False))

        if not risks_df.empty:
            context_parts.append("\n--- Risks and Hypothesis ---")
            display_risks = risks_df.copy()
            display_risks["Score"] = display_risks["likelihood"] * display_risks["impact"]
            context_parts.append(display_risks[["description", "category", "Score", "hypothesis"]].to_markdown(index=False))
        
        ai_context = "\n".join(context_parts)
        
        st.caption("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ AI ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤:")
        with st.expander("‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Context"):
            st.code(ai_context, language="markdown")
            
        st.markdown("üí° **‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ API Key?** ‡∏Ñ‡∏•‡∏¥‡∏Å [‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà](https://playground.opentyphoon.ai/settings/api-key) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ö key ‡∏ü‡∏£‡∏µ!")
        api_key_assist = st.text_input("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å API Key ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£ AI Assist:", type="password", key="api_key_assist")

        if st.button("üöÄ ‡πÉ‡∏´‡πâ AI Assist ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏û‡∏ö", type="primary", use_container_width=True):
            if not api_key_assist:
                st.error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å API Key ‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
            elif not any([plan['plan_title'], plan['objectives'], plan['who'], not logic_df.empty, not kpis_df.empty, not risks_df.empty]):
                 st.error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ú‡∏ô‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô (‡πÄ‡∏ä‡πà‡∏ô ‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏ú‡∏ô, ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå) ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÉ‡∏ô Logic Model/KPIs/Risks ‡∏Å‡πà‡∏≠‡∏ô")
            else:
                with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏à‡∏≤‡∏Å AI..."):
                    try:
                        system_prompt = f"""
‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ PA Assistant ‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô (Performance Audit)
‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå '‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö' ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö ‡πÅ‡∏•‡∏∞‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞‡∏™‡∏¥‡πà‡∏á‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:
1. **‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç (Key Audit Issues)**: ‡πÄ‡∏™‡∏ô‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 3 ‡∏Ç‡πâ‡∏≠ ‡πÇ‡∏î‡∏¢‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏à‡∏≤‡∏Å:
    - ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á‡∏Ç‡∏≠‡∏á Logic Model ‡πÅ‡∏•‡∏∞ KPIs
    - ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÑ‡∏ß‡πâ‡πÉ‡∏ô Risks and Hypothesis
    - ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡∏Ç‡∏≠‡∏á 6W2H ‡πÅ‡∏•‡∏∞‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå
    - ‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏Ñ‡∏ß‡∏£‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏°‡∏ä‡∏±‡∏î‡πÅ‡∏•‡∏∞‡πÄ‡∏ô‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏ú‡∏• ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î
2. **‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏û‡∏ö (Potential Findings)**: ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏™‡∏ô‡∏≠ ‡πÉ‡∏´‡πâ‡∏Ñ‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ß‡πà‡∏≤‡∏≠‡∏≤‡∏à‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏≠‡∏∞‡πÑ‡∏£‡πÑ‡∏î‡πâ‡∏ö‡πâ‡∏≤‡∏á ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏´‡πâ **‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏ö** (‡∏ï‡πà‡∏≥-‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á-‡∏™‡∏π‡∏á)
3. **‡∏™‡∏£‡∏∏‡∏õ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô (Initial Risk Assessment Report)**: ‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡πÇ‡∏î‡∏¢‡πÄ‡∏ô‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡πÅ‡∏•‡∏∞‡∏™‡∏°‡∏°‡∏∏‡∏ï‡∏¥‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
---
**‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö:**
{ai_context}
---
**‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£:**
‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡πÅ‡∏•‡∏∞‡πÅ‡∏ö‡πà‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô 3 ‡∏™‡πà‡∏ß‡∏ô ‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ:
[KEY AUDIT ISSUES]
[‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö Bullet Point]
...
[POTENTIAL FINDINGS]
[‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏û‡∏ö‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏ö ‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö Bullet Point ‡πÇ‡∏î‡∏¢‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á‡∏Å‡∏±‡∏ö Key Audit Issues]
...
[INITIAL RISK ASSESSMENT REPORT]
[‡∏™‡∏£‡∏∏‡∏õ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡∏™‡∏±‡πâ‡∏ô‡πÜ]
"""
                        client = OpenAI(
                            api_key=api_key_assist,
                            base_url="https://api.opentyphoon.ai/v1"
                        )
                        
                        response = client.chat.completions.create(
                            model="typhoon-v2.1-12b-instruct",
                            messages=[{"role": "user", "content": system_prompt}],
                            temperature=0.7,
                            max_tokens=3072,
                            top_p=0.9,
                        )
                        llm_output = response.choices[0].message.content
                        
                        # Parse the output into 3 sections
                        sections = {
                            "issues": "",
                            "findings": "",
                            "report": ""
                        }
                        
                        current_section = None
                        for line in llm_output.split('\n'):
                            line = line.strip()
                            if line == "[KEY AUDIT ISSUES]":
                                current_section = "issues"
                                continue
                            elif line == "[POTENTIAL FINDINGS]":
                                current_section = "findings"
                                continue
                            elif line == "[INITIAL RISK ASSESSMENT REPORT]":
                                current_section = "report"
                                continue
                            
                            if current_section and line:
                                sections[current_section] += line + "\n"
                        
                        st.session_state["gen_issues"] = sections["issues"].strip()
                        st.session_state["gen_findings"] = sections["findings"].strip()
                        st.session_state["gen_report"] = sections["report"].strip()

                        st.success("AI Assist ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
                        st.balloons()
                        # Force a rerun to display the results in the markdown blocks
                        st.rerun() 

                    except Exception as e:
                        error_type = type(e).__name__
                        if error_type in ["AuthenticationError", "RateLimitError"]:
                             error_message = f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ API: ({error_type}) ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö API Key ‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô (Rate Limit) ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì\n‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î: {e}"
                        else:
                             error_message = f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏Ç‡∏ì‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô: ({error_type}) ‡πÇ‡∏õ‡∏£‡∏î‡∏•‡∏≠‡∏á‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á\n‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î: {e}"
                             
                        st.error(error_message)
                        st.session_state["gen_issues"] = ""
                        st.session_state["gen_findings"] = ""
                        st.session_state["gen_report"] = ""

    st.markdown("<h4 style='color:blue;'>‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç</h4>", unsafe_allow_html=True)
    st.markdown(f"<div style='background-color: #f0f2f6; border: 1px solid #ccc; padding: 10px; border-radius: 5px; height: 200px; overflow-y: scroll;'>{st.session_state.get('gen_issues', '‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥')}</div>", unsafe_allow_html=True)
    
    st.markdown("<h4 style='color:blue;'>‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏û‡∏ö (‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÇ‡∏≠‡∏Å‡∏≤‡∏™)</h4>", unsafe_allow_html=True)
    st.markdown(f"<div style='background-color: #f0f2f6; border: 1px solid #ccc; padding: 10px; border-radius: 5px; height: 200px; overflow-y: scroll;'>{st.session_state.get('gen_findings', '‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥')}</div>", unsafe_allow_html=True)

    st.markdown("<h4 style='color:blue;'>‡∏™‡∏£‡∏∏‡∏õ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô</h4>", unsafe_allow_html=True)
    st.markdown(f"<div style='background-color: #f0f2f6; border: 1px solid #ccc; padding: 10px; border-radius: 5px; height: 200px; overflow-y: scroll;'>{st.session_state.get('gen_report', '‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥')}</div>", unsafe_allow_html=True)
    
# ----------------- Tab 9: RAG Chatbot -----------------
with tab_chatbot:
    st.subheader("üí¨ RAG Chatbot - ‡∏ñ‡∏≤‡∏°-‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î")

    # 1. File Uploader and Context Loading
    with st.container(border=True):
        st.markdown("##### ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ñ‡∏≤‡∏°-‡∏ï‡∏≠‡∏ö (RAG Context)")
        
        # Helper function to clear context
        def clear_rag_context():
            st.session_state["uploaded_files_content"] = {}
            st.session_state["rag_docs_context"] = ""
            st.session_state["chatbot_messages"] = []
            st.success("‡∏•‡πâ‡∏≤‡∏á‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÅ‡∏ä‡∏ó‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")

        uploaded_files = st.file_uploader(
            "‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå PDF ‡∏´‡∏£‡∏∑‡∏≠ TXT (‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡∏£‡∏ß‡∏° 100,000 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£)", 
            type=["pdf", "txt"], 
            accept_multiple_files=True,
            key="rag_uploader"
        )
        
        # Load button logic (handles file reading)
        if st.button("üîÑ ‡πÇ‡∏´‡∏•‡∏î/‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏ö‡∏£‡∏¥‡∏ö‡∏ó RAG", type="secondary"):
            if not uploaded_files:
                clear_rag_context()
            else:
                new_files_content = {}
                for file in uploaded_files:
                    file_name = file.name
                    # Check if file is new or modified (based on size)
                    if file_name not in st.session_state["uploaded_files_content"] or file.size != st.session_state["uploaded_files_content"].get(file_name, {}).get("size", 0):
                        
                        file_type = file.type
                        text = ""
                        
                        if "pdf" in file_type:
                            text = read_pdf_text_from_uploaded(file)
                            file_type = "pdf"
                        elif "text/plain" in file_type:
                            # Read as string
                            stringio = StringIO(file.getvalue().decode("utf-8"))
                            text = stringio.read()
                            file_type = "txt"
                        else:
                            # Skip unknown file types
                            continue
                        
                        # Apply character limit
                        text = text[:MAX_CHARS_LIMIT]
                        
                        new_files_content[file_name] = {"type": file_type, "content": text, "size": file.size}
                    else:
                        # Use cached content if file is the same
                        new_files_content[file_name] = st.session_state["uploaded_files_content"][file_name]

                st.session_state["uploaded_files_content"] = new_files_content
                
                # Combine context from session state
                load_rag_context(new_files_content)

        st.button("üóëÔ∏è ‡∏•‡πâ‡∏≤‡∏á‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÅ‡∏•‡∏∞‡πÅ‡∏ä‡∏ó", on_click=clear_rag_context)
        
        # Display current context status
        doc_names = list(st.session_state["uploaded_files_content"].keys())
        context_len = len(st.session_state.get("rag_docs_context", ""))
        st.caption(f"‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó: {', '.join(doc_names) if doc_names else '‡πÑ‡∏°‡πà‡∏°‡∏µ'} | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏£‡∏ß‡∏°: {context_len} ‡∏≠‡∏±‡∏Å‡∏Ç‡∏£‡∏∞")

    st.divider()

    # 2. Chat UI and Logic
    st.markdown("üí° **‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ API Key?** ‡∏Ñ‡∏•‡∏¥‡∏Å [‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà](https://playground.opentyphoon.ai/settings/api-key) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ö key ‡∏ü‡∏£‡∏µ!")
    api_key_chatbot = st.text_input("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å API Key ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£ Chatbot:", type="password", key="api_key_chatbot")

    # Display chat messages
    for message in st.session_state.chatbot_messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # User input
    if prompt := st.chat_input("‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î..."):
        if not api_key_chatbot:
            st.error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å API Key ‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
        else:
            # Add user message to chat history
            st.session_state.chatbot_messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            # Get assistant response (API call)
            with st.chat_message("assistant"):
                # Check for context
                doc_context = st.session_state.get("rag_docs_context", "‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î")
                
                try:
                    client = OpenAI(
                        api_key=api_key_chatbot,
                        base_url="https://api.opentyphoon.ai/v1"
                    )

                    system_prompt = f"""
‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢ Chatbot ‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô (Performance Audit) ‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö
‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å '‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏†‡∏≤‡∏¢‡πÉ‡∏ô' ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å
- ‡∏´‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡∏Ç‡∏±‡∏î‡πÅ‡∏¢‡πâ‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡πÉ‡∏´‡πâ‡∏¢‡∏∂‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å‡πÅ‡∏•‡∏∞‡∏≠‡∏≤‡∏à‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏ñ‡∏∂‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡∏±‡∏î‡πÅ‡∏¢‡πâ‡∏á‡∏ô‡∏±‡πâ‡∏ô
- ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏±‡πâ‡∏á‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏ß‡πà‡∏≤ \"‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏ó‡∏±‡πâ‡∏á‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡∏ú‡∏°\"

---
**‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏†‡∏≤‡∏¢‡πÉ‡∏ô:**
{doc_context}
---

‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô‡∏ô‡∏µ‡πâ ‡∏à‡∏á‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
\"\"\"
"""
                    
                    messages_for_api = [
                        {"role": "system", "content": system_prompt}
                    ]
                    # Add chat history, but keep it concise (last 10 messages including system prompt)
                    for msg in st.session_state.chatbot_messages[-10:]:
                        messages_for_api.append(msg)
                    
                    response_stream = client.chat.completions.create(
                        model="typhoon-v2.1-12b-instruct",
                        messages=messages_for_api,
                        temperature=0.5,
                        max_tokens=3072,
                        stream=True
                    )
                    
                    response = st.write_stream(response_stream)
                    st.session_state.chatbot_messages.append({"role": "assistant", "content": response})

                except Exception as e:
                    error_type = type(e).__name__
                    if error_type in ["AuthenticationError", "RateLimitError"]:
                         error_message = f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ API: ({error_type}) ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö API Key ‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô (Rate Limit) ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì\n‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î: {e}"
                    else:
                         error_message = f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏Ç‡∏ì‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô: ({error_type}) ‡πÇ‡∏õ‡∏£‡∏î‡∏•‡∏≠‡∏á‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á\n‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î: {e}"
                         
                    st.error(error_message)
                    st.session_state.chatbot_messages.append({"role": "assistant", "content": error_message})
