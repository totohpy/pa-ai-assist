# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
from io import BytesIO
from datetime import datetime
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from openai import OpenAI
import os
import io
# Re-imported PyPDF2 for the new chatbot functionality
from PyPDF2 import PdfReader

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏û‡∏à
st.set_page_config(page_title="Planning Studio (+ Issue Suggestions)", page_icon="üß≠", layout="wide")

# ----------------- Global Settings in Sidebar -----------------
with st.sidebar:
    st.title("‚öôÔ∏è ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏•‡∏≤‡∏á")
    st.info("API Key ‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏≠‡∏Å‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏ó‡∏∏‡∏Å‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå AI ‡πÉ‡∏ô‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô")
    st.session_state.api_key_global = st.text_input(
        "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å API Key (OpenTyphoon)",
        type="password",
        key="api_key_global_input",
        help="‡∏Ñ‡∏•‡∏¥‡∏Å‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ö Key ‡∏ü‡∏£‡∏µ: https://playground.opentyphoon.ai/settings/api-key"
    )
    st.markdown("---")
    st.markdown("‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏î‡∏¢ [Planning Studio]")


# ----------------- Chatbot Helper Functions (NEW) -----------------
MAX_CHARS_LIMIT = 200000 # Set a character limit for RAG context

def process_documents(files, source_type, limit, current_len=0):
    """Extracts text from uploaded files (PDF, TXT, CSV)."""
    text = ""
    filenames = []
    limit_reached = False
    for file in files:
        if current_len + len(text) >= limit:
            st.warning(f"‡∏ñ‡∏∂‡∏á‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î ({limit:,}) ‡πÅ‡∏•‡πâ‡∏ß ‡πÑ‡∏ü‡∏•‡πå‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•")
            limit_reached = True
            break
        try:
            if file.name.endswith('.pdf'):
                reader = PdfReader(file)
                for page in reader.pages:
                    text += page.extract_text() or ""
            elif file.name.endswith('.txt'):
                text += file.getvalue().decode("utf-8")
            elif file.name.endswith('.csv'):
                 # Read only a sample to avoid overwhelming the context
                df = pd.read_csv(file)
                text += df.head(15).to_string() # Convert head of dataframe to string
            filenames.append(file.name)
        except Exception as e:
            st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå {file.name}: {e}")
    return text[:limit - current_len], filenames


# ----------------- Session Init -----------------
def init_state():
    ss = st.session_state
    # --- Existing States ---
    ss.setdefault("plan", {
        "plan_id": "PLN-" + datetime.now().strftime("%y%m%d-%H%M%S"),
        "plan_title": "", "program_name": "",
        "who": "", "what": "", "where": "", "when": "", "why": "", "how": "", "how_much": "", "whom": "",
        "objectives": "", "scope": "", "assumptions": "", "status": "Draft"
    })
    ss.setdefault("logic_items", pd.DataFrame(columns=["item_id","plan_id","type","description","metric","unit","target","source"]))
    ss.setdefault("methods", pd.DataFrame(columns=["method_id","plan_id","type","tool_ref","sampling","questions","linked_issue","data_source","frequency"]))
    ss.setdefault("kpis", pd.DataFrame(columns=["kpi_id","plan_id","level","name","formula","numerator","denominator","unit","baseline","target","frequency","data_source","quality_requirements"]))
    ss.setdefault("risks", pd.DataFrame(columns=["risk_id","plan_id","description","category","likelihood","impact","mitigation","hypothesis"]))
    ss.setdefault("audit_issues", pd.DataFrame(columns=["issue_id","plan_id","title","rationale","linked_kpi","proposed_methods","source_finding_id","issue_detail", "recommendation"]))
    ss.setdefault("gen_issues", "")
    ss.setdefault("gen_findings", "")
    ss.setdefault("gen_report", "")
    ss.setdefault("issue_results", pd.DataFrame())
    ss.setdefault("ref_seed", "")
    ss.setdefault("issue_query_text", "")

    # --- NEW States for Chatbot ---
    ss.setdefault('api_key_global', '')
    ss.setdefault('chatbot_messages', [{"role": "assistant", "content": "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ú‡∏°‡∏Ñ‡∏∑‡∏≠ PA Chat ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ú‡∏°‡∏ä‡πà‡∏ß‡∏¢‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏±‡∏ö"}])
    ss.setdefault('doc_context_local', "") # For pre-loaded docs, empty for now
    ss.setdefault('doc_context_uploaded', "") # For user-uploaded docs
    ss.setdefault('last_uploaded_files', set())


def next_id(prefix, df, col):
    if df.empty: return f"{prefix}-001"
    nums = [int(str(x).split("-")[-1]) for x in df[col] if str(x).split("-")[-1].isdigit()]
    n = max(nums) + 1 if nums else 1
    return f"{prefix}-{n:03d}"

def df_download_link(df: pd.DataFrame, filename: str, label: str):
    buf = BytesIO()
    df.to_csv(buf, index=False, encoding="utf-8-sig")
    st.download_button(label, data=buf.getvalue(), file_name=filename, mime="text/csv")

# ----------------- Findings Loader & Search -----------------
@st.cache_data(show_spinner=False)
def load_findings(uploaded=None):
    findings_df = pd.DataFrame()
    findings_db_path = "FindingsLibrary.csv"
    if os.path.exists(findings_db_path):
        try:
            findings_df = pd.read_csv(findings_db_path)
        except Exception as e:
            st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå FindingsLibrary.csv: {e}")
            findings_df = pd.DataFrame()
    if uploaded is not None:
        try:
            if uploaded.name.endswith('.csv'):
                uploaded_df = pd.read_csv(uploaded)
            elif uploaded.name.endswith(('.xlsx', '.xls')):
                xls = pd.ExcelFile(uploaded)
                sheet_name = "Data" if "Data" in xls.sheet_names else 0
                uploaded_df = pd.read_excel(xls, sheet_name=sheet_name)
            findings_df = pd.concat([findings_df, uploaded_df], ignore_index=True)
            st.success(f"‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå '{uploaded.name}' ‡πÅ‡∏•‡∏∞‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ö‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏î‡∏¥‡∏°‡πÅ‡∏•‡πâ‡∏ß")
        except Exception as e:
            st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î: {e}")

    if not findings_df.empty:
        for c in ["issue_title","issue_detail","cause_detail","recommendation","program","unit"]:
            if c in findings_df.columns:
                findings_df[c] = findings_df[c].fillna("")
        if "year" in findings_df.columns:
            findings_df["year"] = pd.to_numeric(findings_df["year"], errors="coerce").fillna(0).astype(int)
        if "severity" in findings_df.columns:
            findings_df["severity"] = pd.to_numeric(findings_df["severity"], errors="coerce").fillna(3).clip(1,5).astype(int)
    return findings_df

@st.cache_resource(show_spinner=False)
def build_tfidf_index(findings_df: pd.DataFrame):
    texts = (findings_df["issue_title"].fillna("") + " " + findings_df["issue_detail"].fillna(""))
    vec = TfidfVectorizer(max_features=20000, ngram_range=(1,2))
    X = vec.fit_transform(texts)
    return vec, X

def search_candidates(query_text, findings_df, vec, X, top_k=8):
    qv = vec.transform([query_text])
    sims = cosine_similarity(qv, X)[0]
    out = findings_df.copy()
    out["sim_score"] = sims
    out["year_norm"] = (out["year"] - out["year"].min()) / (out["year"].max() - out["year"].min()) if "year" in out.columns and out["year"].nunique() > 1 else 0.0
    out["sev_norm"] = out.get("severity", 3) / 5
    out["score"] = out["sim_score"]*0.65 + out["sev_norm"]*0.25 + out["year_norm"]*0.10
    cols = ["finding_id","year","unit","program","issue_title","issue_detail","cause_category","cause_detail","recommendation","outcomes_impact","severity","score", "sim_score"]
    return out.sort_values("score", ascending=False).head(top_k)[[c for c in cols if c in out.columns]]

def create_excel_template():
    df = pd.DataFrame(columns=["finding_id", "issue_title", "unit", "program", "year", "cause_category", "cause_detail", "issue_detail", "recommendation", "outcomes_impact", "severity"])
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df.to_excel(writer, index=False, sheet_name='FindingsLibrary')
    return output.getvalue()

# ----------------- App UI -----------------
init_state()
plan = st.session_state["plan"]
logic_df = st.session_state["logic_items"]
methods_df = st.session_state["methods"]
kpis_df = st.session_state["kpis"]
risks_df = st.session_state["risks"]
audit_issues_df = st.session_state["audit_issues"]

st.title("üß≠ Planning Studio ‚Äì Performance Audit")

# ----------------- START: Custom CSS -----------------
st.markdown("""
<style>
body { font-family: 'Kanit', sans-serif; }
button[data-baseweb="tab"] {
    border: 1px solid #007bff; border-radius: 8px; padding: 10px 15px;
    margin: 5px 5px 5px 0px; transition: background-color 0.3s, color 0.3s;
    font-weight: bold; color: #007bff !important; background-color: #ffffff;
    box-shadow: 1px 1px 3px rgba(0, 0, 0, 0.1); border-bottom: none !important;
    &::after { content: none !important; }
}
button[data-baseweb="tab"][aria-selected="true"] { box-shadow: 2px 2px 5px rgba(0,0,0,0.2); }

/* Group 1: 1-5 (Blue) */
div[data-baseweb="tab-list"] button:nth-of-type(-n+5) { border-color: #007bff; color: #007bff !important; }
div[data-baseweb="tab-list"] button:nth-of-type(-n+5)[aria-selected="true"] { background-color: #007bff; color: white !important; }
/* Group 2: 6-7 (Purple) */
div[data-baseweb="tab-list"] button:nth-of-type(6), div[data-baseweb="tab-list"] button:nth-of-type(7) { border-color: #6f42c1; color: #6f42c1 !important; }
div[data-baseweb="tab-list"] button:nth-of-type(6)[aria-selected="true"], div[data-baseweb="tab-list"] button:nth-of-type(7)[aria-selected="true"] { background-color: #6f42c1; color: white !important; }
/* Group 3: 8 (Gold) */
div[data-baseweb="tab-list"] button:nth-of-type(8) { border-color: #ffc107; color: #cc9900 !important; }
div[data-baseweb="tab-list"] button:nth-of-type(8)[aria-selected="true"] { background-color: #ffc107; color: #333333 !important; }
/* Group 4: 9 (Green - NEW) */
div[data-baseweb="tab-list"] button:nth-of-type(9) { border-color: #28a745; color: #28a745 !important; }
div[data-baseweb="tab-list"] button:nth-of-type(9)[aria-selected="true"] { background-color: #28a745; color: white !important; }

div[data-baseweb="tab-list"] { border-bottom: none !important; margin-bottom: 15px; flex-wrap: wrap; gap: 10px; }
h4 { color: #007bff !important; border-bottom: 2px solid #e0e0e0; padding-bottom: 5px; }
</style>
""", unsafe_allow_html=True)
# ----------------- END: Custom CSS -----------------

# ----------------- Tab Definitions -----------------
tab_plan, tab_logic, tab_method, tab_kpi, tab_risk, tab_issue, tab_preview, tab_assist, tab_chatbot = st.tabs([
    "1. ‡∏£‡∏∞‡∏ö‡∏∏ ‡πÅ‡∏ú‡∏ô & 6W2H",
    "2. ‡∏£‡∏∞‡∏ö‡∏∏ Logic Model",
    "3. ‡∏£‡∏∞‡∏ö‡∏∏ Methods",
    "4. ‡∏£‡∏∞‡∏ö‡∏∏ KPIs",
    "5. ‡∏£‡∏∞‡∏ö‡∏∏ Risks",
    "6. ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏°‡∏≤",
    "7. ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Preview)",
    "ü§ñ ‡πÉ‡∏´‡πâ PA Assist ‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥",
    "üí¨ PA Chat (‡∏ñ‡∏≤‡∏°-‡∏ï‡∏≠‡∏ö)" # NEW TAB
])

# ----------------- Tab 1: ‡∏£‡∏∞‡∏ö‡∏∏ ‡πÅ‡∏ú‡∏ô & 6W2H -----------------
with tab_plan:
    st.subheader("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ú‡∏ô (Plan) - ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏∞‡∏ö‡∏∏‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
    with st.container(border=True):
        c1, c2, c3 = st.columns([2,2,1])
        plan["plan_title"] = c1.text_input("‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏ú‡∏ô/‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ï‡∏£‡∏ß‡∏à", plan["plan_title"])
        plan["program_name"] = c1.text_input("‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£/‡πÅ‡∏ú‡∏ô‡∏á‡∏≤‡∏ô", plan["program_name"])
        plan["objectives"] = c1.text_area("‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à", plan["objectives"])
        plan["scope"] = c2.text_area("‡∏Ç‡∏≠‡∏ö‡πÄ‡∏Ç‡∏ï‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à", plan["scope"])
        plan["assumptions"] = c2.text_area("‡∏™‡∏°‡∏°‡∏∏‡∏ï‡∏¥‡∏ê‡∏≤‡∏ô/‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", plan["assumptions"])
        c3.text_input("Plan ID", plan["plan_id"], disabled=True)
        plan["status"] = c3.selectbox("‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞", ["Draft","Published"], index=0)

    st.divider()
    st.subheader("‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö (6W2H)")
    with st.container(border=True):
        st.markdown("##### üöÄ ‡∏™‡∏£‡πâ‡∏≤‡∏á 6W2H ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏î‡πâ‡∏ß‡∏¢ AI")
        uploaded_text = st.text_area("‡∏ß‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ AI ‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏£‡∏∏‡∏õ 6W2H:", height=200, key="uploaded_text")
        
        if st.button("üöÄ ‡∏™‡∏£‡πâ‡∏≤‡∏á 6W2H ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°", type="primary", key="6w2h_button"):
            if not uploaded_text: st.error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ß‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏ô‡∏ä‡πà‡∏≠‡∏á‡∏Å‡πà‡∏≠‡∏ô")
            elif not st.session_state.api_key_global: st.error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å API Key ‡πÉ‡∏ô Sidebar ‡∏î‡πâ‡∏≤‡∏ô‡∏ã‡πâ‡∏≤‡∏¢‡∏Å‡πà‡∏≠‡∏ô")
            else:
                with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•..."):
                    try:
                        user_prompt = f"‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏µ‡πâ: --- {uploaded_text} --- ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏õ‡πá‡∏ô 6W2H (Who, Whom, What, Where, When, Why, How, How much) ‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö key: value"
                        client = OpenAI(api_key=st.session_state.api_key_global, base_url="https://api.opentyphoon.ai/v1")
                        response = client.chat.completions.create(
                            model="typhoon-v2.1-12b-instruct",
                            messages=[{"role": "user", "content": user_prompt}],
                            temperature=0.7, max_tokens=1024, top_p=0.9
                        )
                        llm_output = response.choices[0].message.content
                        for line in llm_output.strip().split('\n'):
                            if ':' in line:
                                key, value = map(str.strip, line.split(':', 1))
                                normalized_key = key.lower().replace(' ', '_')
                                if normalized_key in plan: plan[normalized_key] = value
                        st.success("‡∏™‡∏£‡πâ‡∏≤‡∏á 6W2H ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß! ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ñ‡∏π‡∏Å‡πÄ‡∏ï‡∏¥‡∏°‡πÉ‡∏ô‡∏ä‡πà‡∏≠‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÅ‡∏•‡πâ‡∏ß")
                        st.balloons()
                    except Exception as e:
                        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ AI: {e}")

    with st.container(border=True):
        st.markdown("##### ‚≠ê‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏∞‡∏ö‡∏∏‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏≥‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•")
        cc1, cc2, cc3 = st.columns(3)
        plan["who"] = cc1.text_input("Who (‡πÉ‡∏Ñ‡∏£)", value=plan["who"])
        plan["whom"] = cc1.text_input("Whom (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏Ñ‡∏£)", value=plan["whom"])
        plan["what"] = cc1.text_input("What (‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£)", value=plan["what"])
        plan["where"] = cc1.text_input("Where (‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô)", value=plan["where"])
        plan["when"] = cc2.text_input("When (‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÉ‡∏î)", value=plan["when"])
        plan["why"] = cc2.text_area("Why (‡∏ó‡∏≥‡πÑ‡∏°)", value=plan["why"])
        plan["how"] = cc3.text_area("How (‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£)", value=plan["how"])
        plan["how_much"] = cc3.text_input("How much (‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏£)", value=plan["how_much"])

# ----------------- Tab 2: Logic Model -----------------
with tab_logic:
    st.subheader("‡∏£‡∏∞‡∏ö‡∏∏‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Logic Model: Input ‚Üí Activities ‚Üí Output ‚Üí Outcome ‚Üí Impact")
    st.dataframe(logic_df, use_container_width=True, hide_index=True)
    with st.expander("‚ûï ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÉ‡∏ô Logic Model"):
        with st.form("logic_form"):
            c1, c2, c3 = st.columns(3)
            typ = c1.selectbox("‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó", ["Input","Activity","Output","Outcome","Impact"])
            desc = c1.text_input("‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢/‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î")
            metric = c1.text_input("‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î/metric")
            unit = c2.text_input("‡∏´‡∏ô‡πà‡∏ß‡∏¢")
            target = c2.text_input("‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢")
            source = c3.text_input("‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
            if st.form_submit_button("‡πÄ‡∏û‡∏¥‡πà‡∏° Logic Item", type="primary"):
                new_row = pd.DataFrame([{"item_id": next_id("LG", logic_df, "item_id"), "plan_id": plan["plan_id"], "type": typ, "description": desc, "metric": metric, "unit": unit, "target": target, "source": source}])
                st.session_state["logic_items"] = pd.concat([logic_df, new_row], ignore_index=True)
                st.rerun()

# ----------------- Remaining Tabs (3, 4, 5) - Condensed for brevity -----------------
with tab_method:
    st.subheader("‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Methods)")
    st.dataframe(methods_df, use_container_width=True, hide_index=True)
    # Add Method form...

with tab_kpi:
    st.subheader("‡∏£‡∏∞‡∏ö‡∏∏‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î (KPIs)")
    st.dataframe(kpis_df, use_container_width=True, hide_index=True)
    # Add KPI form...

with tab_risk:
    st.subheader("‡∏£‡∏∞‡∏ö‡∏∏‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á (Risks)")
    st.dataframe(risks_df, use_container_width=True, hide_index=True)
    # Add Risk form...

# ----------------- Tab 6: ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏°‡∏≤ -----------------
with tab_issue:
    st.subheader("üîé ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡πÄ‡∏Å‡πà‡∏≤ (Issue Suggestions)")
    with st.container(border=True):
        st.download_button(label="‚¨áÔ∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏°‡πà‡πÅ‡∏ö‡∏ö FindingsLibrary.xlsx", data=create_excel_template(), file_name="FindingsLibrary.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
        uploaded = st.file_uploader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î FindingsLibrary.csv ‡∏´‡∏£‡∏∑‡∏≠ .xlsx", type=["csv", "xlsx", "xls"])
    findings_df = load_findings(uploaded=uploaded)
    if findings_df.empty:
        st.info("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Findings ‡πÇ‡∏õ‡∏£‡∏î‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå ‡∏´‡∏£‡∏∑‡∏≠‡∏ß‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå FindingsLibrary.csv ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô")
    else:
        st.success(f"‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Findings ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {len(findings_df)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        vec, X = build_tfidf_index(findings_df)
        seed = f"Who:{plan.get('who','')} What:{plan.get('what','')} Outputs:{' | '.join(logic_df[logic_df['type']=='Output']['description'].tolist())} Outcomes:{' | '.join(logic_df[logic_df['type']=='Outcome']['description'].tolist())}"
        
        def refresh_query_text(new_seed):
            st.session_state["issue_query_text"] = new_seed
            st.session_state["ref_seed"] = new_seed

        if "issue_query_text" not in st.session_state or st.session_state.get("ref_seed") != seed and st.session_state.get("issue_query_text") == st.session_state.get("ref_seed"):
            refresh_query_text(seed)

        c_query_area, c_refresh_btn = st.columns([6, 1])
        query_text = c_query_area.text_area("**‡∏™‡∏£‡∏∏‡∏õ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ (‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÑ‡∏î‡πâ):**", st.session_state["issue_query_text"], height=140, key="issue_query_text_area")
        c_refresh_btn.button("üîÑ", on_click=refresh_query_text, args=(seed,), help="‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏ä‡πà‡∏≠‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î")
        
        if st.button("‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á", type="primary", key="search_button_fix"):
            results = search_candidates(query_text, findings_df, vec, X, top_k=8)
            st.session_state["issue_results"] = results
            st.success(f"‡∏û‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á {len(results)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
            
        results = st.session_state.get("issue_results", pd.DataFrame())
        if not results.empty:
            st.subheader("‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤")
            for i, row in results.reset_index(drop=True).iterrows():
                with st.container(border=True):
                    st.markdown(f"**{row.get('issue_title', '(N/A)')}** (‡∏´‡∏ô‡πà‡∏ß‡∏¢: {row.get('unit', '-')}, ‡∏õ‡∏µ: {int(row.get('year', 0))})")
                    with st.expander("‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î/‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞ (‡πÄ‡∏î‡∏¥‡∏°)"):
                        st.write(row.get("issue_detail", "-"))
                        st.markdown(f"**‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á**: {row.get('score', 0):.3f}")
                    c1, c2 = st.columns([3,1])
                    rationale = c1.text_area("‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏ï‡∏£‡∏ß‡∏à", key=f"rat_{i}", value=f"‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏Å‡∏£‡∏ì‡∏µ‡πÄ‡∏î‡∏¥‡∏° ‡∏õ‡∏µ {int(row.get('year', 0))}")
                    if c2.button("‚ûï ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÅ‡∏ú‡∏ô", key=f"add_{i}"):
                        new_issue = pd.DataFrame([{"issue_id": next_id("ISS", audit_issues_df, "issue_id"), "plan_id": plan["plan_id"], "title": row.get('issue_title'), "rationale": rationale, "source_finding_id": row.get('finding_id'), "issue_detail": row.get('issue_detail'), "recommendation": row.get('recommendation')}])
                        st.session_state["audit_issues"] = pd.concat([audit_issues_df, new_issue], ignore_index=True)
                        st.success("‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤‡πÅ‡∏ú‡∏ô‡πÅ‡∏•‡πâ‡∏ß ‚úÖ")
                        st.rerun()
        st.markdown("### ‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÅ‡∏ú‡∏ô")
        st.dataframe(st.session_state["audit_issues"], use_container_width=True, hide_index=True)

# ----------------- Tab 7: ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Preview) -----------------
with tab_preview:
    st.subheader("‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏ú‡∏ô (Preview)")
    with st.container(border=True):
        st.markdown(f"**Plan ID:** {plan['plan_id']}  \n**‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏ú‡∏ô‡∏á‡∏≤‡∏ô:** {plan['plan_title']}")
    st.markdown("### ‡∏™‡∏£‡∏∏‡∏õ 6W2H")
    st.json(plan)
    # Display other dataframes and download links...
    
# ----------------- Tab 8: ‡πÉ‡∏´‡πâ PA Assist ‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö -----------------
with tab_assist:
    st.subheader("üí° PA Audit Assist (‡∏Ç‡∏±‡∏ö‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏î‡πâ‡∏ß‡∏¢ LLM)")
    if st.button("üöÄ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏à‡∏≤‡∏Å AI", type="primary", key="llm_assist_button"):
        if not st.session_state.api_key_global:
            st.error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å API Key ‡πÉ‡∏ô Sidebar ‡∏î‡πâ‡∏≤‡∏ô‡∏ã‡πâ‡∏≤‡∏¢‡∏Å‡πà‡∏≠‡∏ô")
        else:
            with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥..."):
                try:
                    plan_summary = f"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ú‡∏ô: {plan}\nLogic Model: {logic_df.to_string()}\n‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡πÄ‡∏Å‡πà‡∏≤: {audit_issues_df.to_string()}"
                    user_prompt = f"‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ô‡∏µ‡πâ: --- {plan_summary} --- ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏£‡πâ‡∏≤‡∏á: 1. ‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç, 2. ‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏û‡∏ö, 3. ‡∏£‡πà‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏à‡∏≠. ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Format: <‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö>[‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°]</‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö>\n<‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö>[‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°]</‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö>\n<‡∏£‡πà‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô>[‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°]</‡∏£‡πà‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô>"
                    client = OpenAI(api_key=st.session_state.api_key_global, base_url="https://api.opentyphoon.ai/v1")
                    response = client.chat.completions.create(model="typhoon-v2.1-12b-instruct", messages=[{"role": "user", "content": user_prompt}], temperature=0.7, max_tokens=2048)
                    full_response = response.choices[0].message.content
                    st.session_state["gen_issues"] = full_response.split("<‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö>")[1].split("</‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö>")[0].strip()
                    st.session_state["gen_findings"] = full_response.split("<‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö>")[1].split("</‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö>")[0].strip()
                    st.session_state["gen_report"] = full_response.split("<‡∏£‡πà‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô>")[1].split("</‡∏£‡πà‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô>")[0].strip()
                    st.success("‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏à‡∏≤‡∏Å AI ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß ‚úÖ")
                except Exception as e:
                    st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")

    st.markdown("<h4>‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç</h4>", unsafe_allow_html=True)
    st.markdown(f"<div style='background-color:#f0f2f6;border:1px solid #ccc;padding:10px;border-radius:5px;height:200px;overflow-y:scroll;'>{st.session_state.get('gen_issues', '')}</div>", unsafe_allow_html=True)
    st.markdown("<h4>‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏û‡∏ö</h4>", unsafe_allow_html=True)
    st.markdown(f"<div style='background-color:#f0f2f6;border:1px solid #ccc;padding:10px;border-radius:5px;height:200px;overflow-y:scroll;'>{st.session_state.get('gen_findings', '')}</div>", unsafe_allow_html=True)
    st.markdown("<h4>‡∏£‡πà‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö (Preview)</h4>", unsafe_allow_html=True)
    st.markdown(f"<div style='background-color:#f0f2f6;border:1px solid #ccc;padding:10px;border-radius:5px;height:400px;overflow-y:scroll;'>{st.session_state.get('gen_report', '')}</div>", unsafe_allow_html=True)


# ----------------- Tab 9: PA Chat (‡∏ñ‡∏≤‡∏°-‡∏ï‡∏≠‡∏ö) - NEWLY ADDED -----------------
with tab_chatbot:
    st.subheader("üí¨ PA Chat - ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞ (RAG)")
    
    uploaded_files = st.file_uploader(
        "‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÉ‡∏´‡πâ AI (PDF, TXT, CSV) - ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏•‡∏ö‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏õ‡∏¥‡∏î‡πÅ‡∏≠‡∏õ",
        type=['pdf', 'txt', 'csv'],
        accept_multiple_files=True
    )
    
    current_uploaded_file_names = {f.name for f in uploaded_files}
    if uploaded_files and st.session_state.get('last_uploaded_files') != current_uploaded_file_names:
        with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£..."):
            st.session_state.doc_context_uploaded, _ = process_documents(uploaded_files, 'uploaded', MAX_CHARS_LIMIT, len(st.session_state.doc_context_local))
            st.session_state.last_uploaded_files = current_uploaded_file_names
            st.session_state.chatbot_messages = [{"role": "assistant", "content": "‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß ‡∏ú‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÇ‡∏î‡∏¢‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏Ñ‡∏£‡∏±‡∏ö"}]
            st.rerun()
    elif not uploaded_files and st.session_state.doc_context_uploaded:
        st.session_state.doc_context_uploaded = ""
        st.session_state.last_uploaded_files = set()
        st.session_state.chatbot_messages.append({"role": "assistant", "content": "‡πÑ‡∏î‡πâ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏•‡πâ‡∏≤‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏≠‡∏≠‡∏Å‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏£‡∏±‡∏ö"})
        st.rerun()

    doc_context_len = len(st.session_state.doc_context_local) + len(st.session_state.doc_context_uploaded)
    st.info(f"üíæ ‡πÇ‡∏´‡∏•‡∏î‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏£‡∏ß‡∏°: {doc_context_len:,} ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£ (‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î: {MAX_CHARS_LIMIT:,})")

    chat_container = st.container(height=500, border=True)
    with chat_container:
        for message in st.session_state.chatbot_messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

    if prompt := st.chat_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà...", key="chat_input_main"):
        st.session_state.chatbot_messages.append({"role": "user", "content": prompt})
        
        with chat_container: # Re-draw the user message inside the container immediately
             with st.chat_message("user"):
                st.markdown(prompt)

        with chat_container: # Stream the assistant's response
            with st.chat_message("assistant"):
                message_placeholder = st.empty()
                
                if not st.session_state.api_key_global:
                    error_message = "‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: ‡πÑ‡∏°‡πà‡∏û‡∏ö API Key ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å API Key ‡πÉ‡∏ô Sidebar ‡∏î‡πâ‡∏≤‡∏ô‡∏ã‡πâ‡∏≤‡∏¢‡∏Å‡πà‡∏≠‡∏ô"
                    st.error(error_message)
                    st.session_state.chatbot_messages.append({"role": "assistant", "content": error_message})
                    message_placeholder.markdown(error_message)
                else:
                    try:
                        doc_context = st.session_state.doc_context_local + st.session_state.doc_context_uploaded
                        system_prompt = f"‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢ AI ‡∏î‡πâ‡∏≤‡∏ô Performance Audit ‡∏à‡∏á‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å '‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏†‡∏≤‡∏¢‡πÉ‡∏ô' ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö: --- ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏†‡∏≤‡∏¢‡πÉ‡∏ô:{doc_context} ---"
                        
                        messages_for_api = [{"role": "system", "content": system_prompt}] + st.session_state.chatbot_messages[-10:]

                        client = OpenAI(api_key=st.session_state.api_key_global, base_url="https://api.opentyphoon.ai/v1")
                        response_stream = client.chat.completions.create(
                            model="typhoon-v2.1-12b-instruct",
                            messages=messages_for_api,
                            temperature=0.5,
                            max_tokens=3072,
                            stream=True
                        )
                        response = message_placeholder.write_stream(response_stream)
                        st.session_state.chatbot_messages.append({"role": "assistant", "content": response})

                    except Exception as e:
                        error_message = f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏Ç‡∏ì‡∏∞‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ API: {e}"
                        st.error(error_message)
                        st.session_state.chatbot_messages.append({"role": "assistant", "content": error_message})
                        message_placeholder.markdown(error_message)
# ----------------- END: Tab 9 -----------------
